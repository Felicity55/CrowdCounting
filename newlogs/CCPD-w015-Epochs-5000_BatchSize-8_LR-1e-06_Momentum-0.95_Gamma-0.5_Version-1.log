2022-12-29 17:10:38,761 - main - INFO - CCPD-w015-Epochs-5000_BatchSize-8_LR-1e-06_Momentum-0.95_Gamma-0.5_Version-1
2022-12-29 17:10:46,737 - main - INFO - Epoch 1/5000
2022-12-29 17:10:46,737 - main - INFO - ----------------------------
2022-12-29 17:10:46,738 - main - INFO - training...
2022-12-29 18:32:05,638 - main - INFO - CCPD-w015-Epochs-5000_BatchSize-8_LR-1e-06_Momentum-0.95_Gamma-0.5_Version-1
2022-12-29 18:32:13,014 - main - INFO - Epoch 1/5000
2022-12-29 18:32:13,014 - main - INFO - ----------------------------
2022-12-29 18:32:13,014 - main - INFO - training...
2022-12-29 18:41:33,381 - main - DEBUG - Batch 500: running loss = 1667756.9426
2022-12-29 18:50:48,154 - main - DEBUG - Batch 1000: running loss = 3274602.0247
2022-12-29 18:59:37,460 - main - INFO - Epoch 1 - train: epoch loss = 3217.4204
2022-12-29 18:59:37,460 - main - INFO - validating...
2022-12-29 19:06:24,950 - main - DEBUG - Batch 500: running loss = 1533077.1807
2022-12-29 19:06:30,786 - main - INFO - Epoch 1 - val: epoch loss = 3066.4949
2022-12-29 19:06:30,971 - main - INFO - Saved the best model at epoch 1.
2022-12-29 19:06:30,971 - main - INFO - Epoch 2/5000
2022-12-29 19:06:30,971 - main - INFO - ----------------------------
2022-12-29 19:06:30,971 - main - INFO - training...
2022-12-29 19:15:44,707 - main - DEBUG - Batch 500: running loss = 1496207.4048
2022-12-29 19:24:58,676 - main - DEBUG - Batch 1000: running loss = 2940485.1426
2022-12-29 19:33:47,933 - main - INFO - Epoch 2 - train: epoch loss = 2892.0435
2022-12-29 19:33:47,933 - main - INFO - validating...
2022-12-29 19:40:34,758 - main - DEBUG - Batch 500: running loss = 1373058.0000
2022-12-29 19:40:40,452 - main - INFO - Epoch 2 - val: epoch loss = 2746.4949
2022-12-29 19:40:40,611 - main - INFO - Saved the best model at epoch 2.
2022-12-29 19:40:40,611 - main - INFO - Epoch 3/5000
2022-12-29 19:40:40,611 - main - INFO - ----------------------------
2022-12-29 19:40:40,611 - main - INFO - training...
2022-12-29 19:49:54,454 - main - DEBUG - Batch 500: running loss = 1350408.6323
2022-12-29 19:59:08,357 - main - DEBUG - Batch 1000: running loss = 2656906.8999
2022-12-29 20:07:58,022 - main - INFO - Epoch 3 - train: epoch loss = 2615.8314
2022-12-29 20:07:58,023 - main - INFO - validating...
2022-12-29 20:14:45,999 - main - DEBUG - Batch 500: running loss = 1242918.1372
2022-12-29 20:14:51,720 - main - INFO - Epoch 3 - val: epoch loss = 2486.2210
2022-12-29 20:14:51,883 - main - INFO - Saved the best model at epoch 3.
2022-12-29 20:14:51,884 - main - INFO - Epoch 4/5000
2022-12-29 20:14:51,884 - main - INFO - ----------------------------
2022-12-29 20:14:51,885 - main - INFO - training...
2022-12-29 20:24:04,992 - main - DEBUG - Batch 500: running loss = 1227021.3167
2022-12-29 20:33:18,522 - main - DEBUG - Batch 1000: running loss = 2416356.9387
2022-12-29 20:42:08,391 - main - INFO - Epoch 4 - train: epoch loss = 2381.2360
2022-12-29 20:42:08,392 - main - INFO - validating...
2022-12-29 20:48:56,635 - main - DEBUG - Batch 500: running loss = 1129673.5518
2022-12-29 20:49:02,288 - main - INFO - Epoch 4 - val: epoch loss = 2259.7229
2022-12-29 20:49:02,476 - main - INFO - Saved the best model at epoch 4.
2022-12-29 20:49:02,476 - main - INFO - Epoch 5/5000
2022-12-29 20:49:02,477 - main - INFO - ----------------------------
2022-12-29 20:49:02,477 - main - INFO - training...
2022-12-29 20:58:15,437 - main - DEBUG - Batch 500: running loss = 1121682.7068
2022-12-29 21:07:29,408 - main - DEBUG - Batch 1000: running loss = 2211210.9353
2022-12-29 21:16:19,148 - main - INFO - Epoch 5 - train: epoch loss = 2181.2609
2022-12-29 21:16:19,149 - main - INFO - validating...
2022-12-29 21:23:06,195 - main - DEBUG - Batch 500: running loss = 1028128.5892
2022-12-29 21:23:11,860 - main - INFO - Epoch 5 - val: epoch loss = 2056.6144
2022-12-29 21:23:12,023 - main - INFO - Saved the best model at epoch 5.
2022-12-29 21:23:12,023 - main - INFO - Epoch 6/5000
2022-12-29 21:23:12,023 - main - INFO - ----------------------------
2022-12-29 21:23:12,028 - main - INFO - training...
2022-12-29 21:32:24,972 - main - DEBUG - Batch 500: running loss = 1031685.8964
2022-12-29 21:41:39,155 - main - DEBUG - Batch 1000: running loss = 2035742.7639
2022-12-29 21:50:28,621 - main - INFO - Epoch 6 - train: epoch loss = 2010.0716
2022-12-29 21:50:28,621 - main - INFO - validating...
2022-12-29 21:57:15,379 - main - DEBUG - Batch 500: running loss = 945768.5435
2022-12-29 21:57:21,082 - main - INFO - Epoch 6 - val: epoch loss = 1891.8861
2022-12-29 21:57:21,242 - main - INFO - Saved the best model at epoch 6.
2022-12-29 21:57:21,242 - main - INFO - Epoch 7/5000
2022-12-29 21:57:21,242 - main - INFO - ----------------------------
2022-12-29 21:57:21,242 - main - INFO - training...
2022-12-29 22:06:34,355 - main - DEBUG - Batch 500: running loss = 954486.8372
2022-12-29 22:15:48,331 - main - DEBUG - Batch 1000: running loss = 1885083.2172
2022-12-29 22:24:37,474 - main - INFO - Epoch 7 - train: epoch loss = 1862.7711
2022-12-29 22:24:37,474 - main - INFO - validating...
2022-12-29 22:31:24,562 - main - DEBUG - Batch 500: running loss = 875881.9573
2022-12-29 22:31:30,242 - main - INFO - Epoch 7 - val: epoch loss = 1752.0956
2022-12-29 22:31:30,403 - main - INFO - Saved the best model at epoch 7.
2022-12-29 22:31:30,403 - main - INFO - Epoch 8/5000
2022-12-29 22:31:30,403 - main - INFO - ----------------------------
2022-12-29 22:31:30,409 - main - INFO - training...
2022-12-29 22:40:43,656 - main - DEBUG - Batch 500: running loss = 887787.3977
2022-12-29 22:49:57,405 - main - DEBUG - Batch 1000: running loss = 1754732.3136
2022-12-29 22:58:46,558 - main - INFO - Epoch 8 - train: epoch loss = 1735.5313
2022-12-29 22:58:46,558 - main - INFO - validating...
2022-12-29 23:05:33,976 - main - DEBUG - Batch 500: running loss = 815538.3817
2022-12-29 23:05:39,669 - main - INFO - Epoch 8 - val: epoch loss = 1631.3997
2022-12-29 23:05:39,820 - main - INFO - Saved the best model at epoch 8.
2022-12-29 23:05:39,820 - main - INFO - Epoch 9/5000
2022-12-29 23:05:39,820 - main - INFO - ----------------------------
2022-12-29 23:05:39,831 - main - INFO - training...
2022-12-29 23:14:53,040 - main - DEBUG - Batch 500: running loss = 829705.0076
2022-12-29 23:24:06,705 - main - DEBUG - Batch 1000: running loss = 1641647.0619
2022-12-29 23:32:55,945 - main - INFO - Epoch 9 - train: epoch loss = 1624.8158
2022-12-29 23:32:55,945 - main - INFO - validating...
2022-12-29 23:39:43,060 - main - DEBUG - Batch 500: running loss = 758639.7875
2022-12-29 23:39:48,736 - main - INFO - Epoch 9 - val: epoch loss = 1517.6086
2022-12-29 23:39:48,897 - main - INFO - Saved the best model at epoch 9.
2022-12-29 23:39:48,897 - main - INFO - Epoch 10/5000
2022-12-29 23:39:48,897 - main - INFO - ----------------------------
2022-12-29 23:39:48,903 - main - INFO - training...
2022-12-29 23:49:01,824 - main - DEBUG - Batch 500: running loss = 779253.7261
2022-12-29 23:58:15,309 - main - DEBUG - Batch 1000: running loss = 1542511.4628
2022-12-30 00:07:04,802 - main - INFO - Epoch 10 - train: epoch loss = 1527.9758
2022-12-30 00:07:04,803 - main - INFO - validating...
2022-12-30 00:13:52,030 - main - DEBUG - Batch 500: running loss = 711159.0479
2022-12-30 00:13:57,697 - main - INFO - Epoch 10 - val: epoch loss = 1422.6333
2022-12-30 00:13:57,856 - main - INFO - Saved the best model at epoch 10.
2022-12-30 00:13:57,856 - main - INFO - Epoch 11/5000
2022-12-30 00:13:57,856 - main - INFO - ----------------------------
2022-12-30 00:13:57,863 - main - INFO - training...
2022-12-30 00:23:10,753 - main - DEBUG - Batch 500: running loss = 734921.2739
2022-12-30 00:32:24,286 - main - DEBUG - Batch 1000: running loss = 1455522.5649
2022-12-30 00:41:14,019 - main - INFO - Epoch 11 - train: epoch loss = 1442.7801
2022-12-30 00:41:14,019 - main - INFO - validating...
2022-12-30 00:48:01,120 - main - DEBUG - Batch 500: running loss = 671771.1713
2022-12-30 00:48:06,785 - main - INFO - Epoch 11 - val: epoch loss = 1343.8349
2022-12-30 00:48:06,945 - main - INFO - Saved the best model at epoch 11.
2022-12-30 00:48:06,945 - main - INFO - Epoch 12/5000
2022-12-30 00:48:06,945 - main - INFO - ----------------------------
2022-12-30 00:48:06,951 - main - INFO - training...
2022-12-30 00:57:19,873 - main - DEBUG - Batch 500: running loss = 695568.9041
2022-12-30 01:06:33,839 - main - DEBUG - Batch 1000: running loss = 1379109.0348
2022-12-30 01:15:23,286 - main - INFO - Epoch 12 - train: epoch loss = 1367.4617
2022-12-30 01:15:23,290 - main - INFO - validating...
2022-12-30 01:22:10,317 - main - DEBUG - Batch 500: running loss = 631772.6005
2022-12-30 01:22:15,986 - main - INFO - Epoch 12 - val: epoch loss = 1263.8567
2022-12-30 01:22:16,147 - main - INFO - Saved the best model at epoch 12.
2022-12-30 01:22:16,147 - main - INFO - Epoch 13/5000
2022-12-30 01:22:16,147 - main - INFO - ----------------------------
2022-12-30 01:22:16,151 - main - INFO - training...
2022-12-30 01:31:29,270 - main - DEBUG - Batch 500: running loss = 661075.4806
2022-12-30 01:40:43,163 - main - DEBUG - Batch 1000: running loss = 1310900.9302
2022-12-30 01:49:32,252 - main - INFO - Epoch 13 - train: epoch loss = 1300.7351
2022-12-30 01:49:32,253 - main - INFO - validating...
2022-12-30 01:56:19,157 - main - DEBUG - Batch 500: running loss = 603951.6517
2022-12-30 01:56:24,834 - main - INFO - Epoch 13 - val: epoch loss = 1208.1794
2022-12-30 01:56:24,996 - main - INFO - Saved the best model at epoch 13.
2022-12-30 01:56:24,997 - main - INFO - Epoch 14/5000
2022-12-30 01:56:24,997 - main - INFO - ----------------------------
2022-12-30 01:56:24,998 - main - INFO - training...
2022-12-30 02:05:38,177 - main - DEBUG - Batch 500: running loss = 630268.2731
2022-12-30 02:14:51,903 - main - DEBUG - Batch 1000: running loss = 1250700.1161
2022-12-30 02:23:41,101 - main - INFO - Epoch 14 - train: epoch loss = 1241.1105
2022-12-30 02:23:41,104 - main - INFO - validating...
2022-12-30 02:30:28,487 - main - DEBUG - Batch 500: running loss = 572110.8206
2022-12-30 02:30:34,160 - main - INFO - Epoch 14 - val: epoch loss = 1144.4275
2022-12-30 02:30:34,317 - main - INFO - Saved the best model at epoch 14.
2022-12-30 02:30:34,317 - main - INFO - Epoch 15/5000
2022-12-30 02:30:34,317 - main - INFO - ----------------------------
2022-12-30 02:30:34,325 - main - INFO - training...
2022-12-30 02:39:47,517 - main - DEBUG - Batch 500: running loss = 602409.3551
2022-12-30 02:49:01,136 - main - DEBUG - Batch 1000: running loss = 1196249.2322
2022-12-30 02:57:50,303 - main - INFO - Epoch 15 - train: epoch loss = 1187.5907
2022-12-30 02:57:50,303 - main - INFO - validating...
2022-12-30 03:04:37,497 - main - DEBUG - Batch 500: running loss = 543875.8933
2022-12-30 03:04:43,154 - main - INFO - Epoch 15 - val: epoch loss = 1087.9913
2022-12-30 03:04:43,319 - main - INFO - Saved the best model at epoch 15.
2022-12-30 03:04:43,319 - main - INFO - Epoch 16/5000
2022-12-30 03:04:43,319 - main - INFO - ----------------------------
2022-12-30 03:04:43,327 - main - INFO - training...
2022-12-30 03:13:56,374 - main - DEBUG - Batch 500: running loss = 577484.3541
2022-12-30 03:23:09,977 - main - DEBUG - Batch 1000: running loss = 1146756.1810
2022-12-30 03:31:59,257 - main - INFO - Epoch 16 - train: epoch loss = 1139.4755
2022-12-30 03:31:59,257 - main - INFO - validating...
2022-12-30 03:38:46,484 - main - DEBUG - Batch 500: running loss = 522669.2369
2022-12-30 03:38:52,154 - main - INFO - Epoch 16 - val: epoch loss = 1045.6030
2022-12-30 03:38:52,315 - main - INFO - Saved the best model at epoch 16.
2022-12-30 03:38:52,315 - main - INFO - Epoch 17/5000
2022-12-30 03:38:52,325 - main - INFO - ----------------------------
2022-12-30 03:38:52,325 - main - INFO - training...
2022-12-30 03:48:05,204 - main - DEBUG - Batch 500: running loss = 554816.2615
2022-12-30 03:57:18,840 - main - DEBUG - Batch 1000: running loss = 1102981.6519
2022-12-30 04:06:08,237 - main - INFO - Epoch 17 - train: epoch loss = 1096.0725
2022-12-30 04:06:08,237 - main - INFO - validating...
2022-12-30 04:12:55,354 - main - DEBUG - Batch 500: running loss = 498454.0319
2022-12-30 04:13:01,068 - main - INFO - Epoch 17 - val: epoch loss = 997.1473
2022-12-30 04:13:01,236 - main - INFO - Saved the best model at epoch 17.
2022-12-30 04:13:01,236 - main - INFO - Epoch 18/5000
2022-12-30 04:13:01,236 - main - INFO - ----------------------------
2022-12-30 04:13:01,236 - main - INFO - training...
2022-12-30 04:22:14,161 - main - DEBUG - Batch 500: running loss = 535294.4553
2022-12-30 04:31:27,967 - main - DEBUG - Batch 1000: running loss = 1063344.3896
2022-12-30 04:40:17,200 - main - INFO - Epoch 18 - train: epoch loss = 1056.7242
2022-12-30 04:40:17,200 - main - INFO - validating...
2022-12-30 04:47:04,374 - main - DEBUG - Batch 500: running loss = 480025.3253
2022-12-30 04:47:10,048 - main - INFO - Epoch 18 - val: epoch loss = 960.2582
2022-12-30 04:47:10,213 - main - INFO - Saved the best model at epoch 18.
2022-12-30 04:47:10,213 - main - INFO - Epoch 19/5000
2022-12-30 04:47:10,213 - main - INFO - ----------------------------
2022-12-30 04:47:10,215 - main - INFO - training...
2022-12-30 04:56:23,317 - main - DEBUG - Batch 500: running loss = 515370.9662
2022-12-30 05:05:37,250 - main - DEBUG - Batch 1000: running loss = 1026259.7298
2022-12-30 05:14:26,363 - main - INFO - Epoch 19 - train: epoch loss = 1020.7893
2022-12-30 05:14:26,363 - main - INFO - validating...
2022-12-30 05:21:13,528 - main - DEBUG - Batch 500: running loss = 456134.9529
2022-12-30 05:21:19,201 - main - INFO - Epoch 19 - val: epoch loss = 912.4527
2022-12-30 05:21:19,362 - main - INFO - Saved the best model at epoch 19.
2022-12-30 05:21:19,362 - main - INFO - Epoch 20/5000
2022-12-30 05:21:19,362 - main - INFO - ----------------------------
2022-12-30 05:21:19,365 - main - INFO - training...
2022-12-30 05:30:32,447 - main - DEBUG - Batch 500: running loss = 498609.1785
2022-12-30 05:39:46,200 - main - DEBUG - Batch 1000: running loss = 992477.1387
2022-12-30 05:48:35,444 - main - INFO - Epoch 20 - train: epoch loss = 987.9332
2022-12-30 05:48:35,445 - main - INFO - validating...
2022-12-30 05:55:22,945 - main - DEBUG - Batch 500: running loss = 445578.6851
2022-12-30 05:55:28,645 - main - INFO - Epoch 20 - val: epoch loss = 891.3685
2022-12-30 05:55:28,806 - main - INFO - Saved the best model at epoch 20.
2022-12-30 05:55:28,806 - main - INFO - Epoch 21/5000
2022-12-30 05:55:28,806 - main - INFO - ----------------------------
2022-12-30 05:55:28,809 - main - INFO - training...
2022-12-30 06:04:41,994 - main - DEBUG - Batch 500: running loss = 484371.0491
2022-12-30 06:13:55,617 - main - DEBUG - Batch 1000: running loss = 962578.5425
2022-12-30 06:22:44,950 - main - INFO - Epoch 21 - train: epoch loss = 957.9831
2022-12-30 06:22:44,950 - main - INFO - validating...
2022-12-30 06:29:32,231 - main - DEBUG - Batch 500: running loss = 429061.5998
2022-12-30 06:29:37,898 - main - INFO - Epoch 21 - val: epoch loss = 858.3324
2022-12-30 06:29:38,062 - main - INFO - Saved the best model at epoch 21.
2022-12-30 06:29:38,062 - main - INFO - Epoch 22/5000
2022-12-30 06:29:38,062 - main - INFO - ----------------------------
2022-12-30 06:29:38,065 - main - INFO - training...
2022-12-30 06:38:50,928 - main - DEBUG - Batch 500: running loss = 469701.5449
2022-12-30 06:48:04,473 - main - DEBUG - Batch 1000: running loss = 934332.2184
2022-12-30 06:56:53,790 - main - INFO - Epoch 22 - train: epoch loss = 930.5376
2022-12-30 06:56:53,790 - main - INFO - validating...
2022-12-30 07:03:41,101 - main - DEBUG - Batch 500: running loss = 413533.7675
2022-12-30 07:03:46,767 - main - INFO - Epoch 22 - val: epoch loss = 827.2588
2022-12-30 07:03:46,919 - main - INFO - Saved the best model at epoch 22.
2022-12-30 07:03:46,919 - main - INFO - Epoch 23/5000
2022-12-30 07:03:46,919 - main - INFO - ----------------------------
2022-12-30 07:03:46,929 - main - INFO - training...
2022-12-30 07:12:59,818 - main - DEBUG - Batch 500: running loss = 457758.0596
2022-12-30 07:22:13,347 - main - DEBUG - Batch 1000: running loss = 909985.6191
2022-12-30 07:31:03,034 - main - INFO - Epoch 23 - train: epoch loss = 905.1713
2022-12-30 07:31:03,034 - main - INFO - validating...
2022-12-30 07:37:50,172 - main - DEBUG - Batch 500: running loss = 401125.8928
2022-12-30 07:37:55,838 - main - INFO - Epoch 23 - val: epoch loss = 802.4242
2022-12-30 07:37:55,998 - main - INFO - Saved the best model at epoch 23.
2022-12-30 07:37:55,998 - main - INFO - Epoch 24/5000
2022-12-30 07:37:55,998 - main - INFO - ----------------------------
2022-12-30 07:37:56,002 - main - INFO - training...
2022-12-30 07:47:08,781 - main - DEBUG - Batch 500: running loss = 444411.7025
2022-12-30 07:56:22,787 - main - DEBUG - Batch 1000: running loss = 885248.9514
2022-12-30 08:05:12,250 - main - INFO - Epoch 24 - train: epoch loss = 881.8806
2022-12-30 08:05:12,250 - main - INFO - validating...
2022-12-30 08:11:59,435 - main - DEBUG - Batch 500: running loss = 384777.0770
2022-12-30 08:12:05,105 - main - INFO - Epoch 24 - val: epoch loss = 769.7527
2022-12-30 08:12:05,259 - main - INFO - Saved the best model at epoch 24.
2022-12-30 08:12:05,259 - main - INFO - Epoch 25/5000
2022-12-30 08:12:05,259 - main - INFO - ----------------------------
2022-12-30 08:12:05,269 - main - INFO - training...
2022-12-30 08:21:18,128 - main - DEBUG - Batch 500: running loss = 434804.5098
2022-12-30 08:30:32,202 - main - DEBUG - Batch 1000: running loss = 863526.1662
2022-12-30 08:39:21,323 - main - INFO - Epoch 25 - train: epoch loss = 860.0977
2022-12-30 08:39:21,327 - main - INFO - validating...
2022-12-30 08:46:08,681 - main - DEBUG - Batch 500: running loss = 378761.3846
2022-12-30 08:46:14,361 - main - INFO - Epoch 25 - val: epoch loss = 757.7103
2022-12-30 08:46:14,532 - main - INFO - Saved the best model at epoch 25.
2022-12-30 08:46:14,532 - main - INFO - Epoch 26/5000
2022-12-30 08:46:14,532 - main - INFO - ----------------------------
2022-12-30 08:46:14,536 - main - INFO - training...
2022-12-30 08:55:27,790 - main - DEBUG - Batch 500: running loss = 423450.3235
2022-12-30 09:04:41,607 - main - DEBUG - Batch 1000: running loss = 844283.1810
2022-12-30 09:13:30,692 - main - INFO - Epoch 26 - train: epoch loss = 839.8970
2022-12-30 09:13:30,692 - main - INFO - validating...
2022-12-30 09:20:18,081 - main - DEBUG - Batch 500: running loss = 368847.7354
2022-12-30 09:20:23,798 - main - INFO - Epoch 26 - val: epoch loss = 737.8783
2022-12-30 09:20:23,949 - main - INFO - Saved the best model at epoch 26.
2022-12-30 09:20:23,959 - main - INFO - Epoch 27/5000
2022-12-30 09:20:23,959 - main - INFO - ----------------------------
2022-12-30 09:20:23,960 - main - INFO - training...
2022-12-30 09:29:37,244 - main - DEBUG - Batch 500: running loss = 412401.1069
2022-12-30 09:38:50,797 - main - DEBUG - Batch 1000: running loss = 823499.4779
2022-12-30 09:47:39,940 - main - INFO - Epoch 27 - train: epoch loss = 821.2674
2022-12-30 09:47:39,945 - main - INFO - validating...
2022-12-30 09:54:27,081 - main - DEBUG - Batch 500: running loss = 353491.7635
2022-12-30 09:54:32,758 - main - INFO - Epoch 27 - val: epoch loss = 707.1742
2022-12-30 09:54:32,922 - main - INFO - Saved the best model at epoch 27.
2022-12-30 09:54:32,922 - main - INFO - Epoch 28/5000
2022-12-30 09:54:32,922 - main - INFO - ----------------------------
2022-12-30 09:54:32,932 - main - INFO - training...
2022-12-30 10:03:45,937 - main - DEBUG - Batch 500: running loss = 405062.7228
2022-12-30 10:12:59,466 - main - DEBUG - Batch 1000: running loss = 806673.0847
2022-12-30 10:21:48,763 - main - INFO - Epoch 28 - train: epoch loss = 804.0425
2022-12-30 10:21:48,765 - main - INFO - validating...
2022-12-30 10:28:36,598 - main - DEBUG - Batch 500: running loss = 353514.5273
2022-12-30 10:28:42,284 - main - INFO - Epoch 28 - val: epoch loss = 707.1879
2022-12-30 10:28:42,284 - main - INFO - Epoch 29/5000
2022-12-30 10:28:42,294 - main - INFO - ----------------------------
2022-12-30 10:28:42,294 - main - INFO - training...
2022-12-30 10:37:55,097 - main - DEBUG - Batch 500: running loss = 396726.1570
2022-12-30 10:47:08,780 - main - DEBUG - Batch 1000: running loss = 790700.5750
2022-12-30 10:56:22,451 - main - INFO - Epoch 29 - train: epoch loss = 787.7376
2022-12-30 10:56:22,456 - main - INFO - validating...
2022-12-30 11:03:37,590 - main - DEBUG - Batch 500: running loss = 339445.0477
2022-12-30 11:03:43,585 - main - INFO - Epoch 29 - val: epoch loss = 679.0705
2022-12-30 11:03:43,766 - main - INFO - Saved the best model at epoch 29.
2022-12-30 11:03:43,766 - main - INFO - Epoch 30/5000
2022-12-30 11:03:43,767 - main - INFO - ----------------------------
2022-12-30 11:03:43,768 - main - INFO - training...
2022-12-30 11:13:34,678 - main - DEBUG - Batch 500: running loss = 389807.1682
2022-12-30 11:23:26,155 - main - DEBUG - Batch 1000: running loss = 775858.1865
2022-12-30 11:32:49,268 - main - INFO - Epoch 30 - train: epoch loss = 772.6639
2022-12-30 11:32:49,270 - main - INFO - validating...
2022-12-30 11:40:02,220 - main - DEBUG - Batch 500: running loss = 330507.8915
2022-12-30 11:40:08,213 - main - INFO - Epoch 30 - val: epoch loss = 661.1910
2022-12-30 11:40:08,392 - main - INFO - Saved the best model at epoch 30.
2022-12-30 11:40:08,393 - main - INFO - Epoch 31/5000
2022-12-30 11:40:08,393 - main - INFO - ----------------------------
2022-12-30 11:40:08,394 - main - INFO - training...
2022-12-30 11:49:56,693 - main - DEBUG - Batch 500: running loss = 380914.0399
2022-12-30 11:59:48,579 - main - DEBUG - Batch 1000: running loss = 760440.3098
2022-12-30 12:09:13,433 - main - INFO - Epoch 31 - train: epoch loss = 758.3996
2022-12-30 12:09:13,434 - main - INFO - validating...
2022-12-30 12:16:32,280 - main - DEBUG - Batch 500: running loss = 323744.4365
2022-12-30 12:16:38,258 - main - INFO - Epoch 31 - val: epoch loss = 647.6313
2022-12-30 12:16:38,443 - main - INFO - Saved the best model at epoch 31.
2022-12-30 12:16:38,444 - main - INFO - Epoch 32/5000
2022-12-30 12:16:38,444 - main - INFO - ----------------------------
2022-12-30 12:16:38,445 - main - INFO - training...
2022-12-30 12:26:30,101 - main - DEBUG - Batch 500: running loss = 374173.5630
2022-12-30 12:36:21,998 - main - DEBUG - Batch 1000: running loss = 746992.5137
2022-12-30 12:45:48,152 - main - INFO - Epoch 32 - train: epoch loss = 745.0458
2022-12-30 12:45:48,153 - main - INFO - validating...
2022-12-30 12:53:03,728 - main - DEBUG - Batch 500: running loss = 316340.1251
2022-12-30 12:53:09,718 - main - INFO - Epoch 32 - val: epoch loss = 632.8146
2022-12-30 12:53:09,912 - main - INFO - Saved the best model at epoch 32.
2022-12-30 12:53:09,913 - main - INFO - Epoch 33/5000
2022-12-30 12:53:09,913 - main - INFO - ----------------------------
2022-12-30 12:53:09,914 - main - INFO - training...
2022-12-30 13:02:59,519 - main - DEBUG - Batch 500: running loss = 366895.3613
2022-12-30 13:12:49,224 - main - DEBUG - Batch 1000: running loss = 734563.5302
2022-12-30 13:22:12,532 - main - INFO - Epoch 33 - train: epoch loss = 732.5724
2022-12-30 13:22:12,533 - main - INFO - validating...
2022-12-30 13:29:28,757 - main - DEBUG - Batch 500: running loss = 312681.2772
2022-12-30 13:29:34,969 - main - INFO - Epoch 33 - val: epoch loss = 625.5016
2022-12-30 13:29:35,149 - main - INFO - Saved the best model at epoch 33.
2022-12-30 13:29:35,150 - main - INFO - Epoch 34/5000
2022-12-30 13:29:35,150 - main - INFO - ----------------------------
2022-12-30 13:29:35,151 - main - INFO - training...
2022-12-30 13:39:23,495 - main - DEBUG - Batch 500: running loss = 361735.6754
2022-12-30 13:49:16,507 - main - DEBUG - Batch 1000: running loss = 722756.4498
2022-12-30 13:58:06,737 - main - INFO - Epoch 34 - train: epoch loss = 720.6112
2022-12-30 13:58:06,739 - main - INFO - validating...
2022-12-30 14:04:57,789 - main - DEBUG - Batch 500: running loss = 304417.6039
2022-12-30 14:05:03,503 - main - INFO - Epoch 34 - val: epoch loss = 608.9631
2022-12-30 14:05:03,668 - main - INFO - Saved the best model at epoch 34.
2022-12-30 14:05:03,669 - main - INFO - Epoch 35/5000
2022-12-30 14:05:03,669 - main - INFO - ----------------------------
2022-12-30 14:05:03,670 - main - INFO - training...
2022-12-30 14:14:17,727 - main - DEBUG - Batch 500: running loss = 356747.5289
2022-12-30 14:23:32,554 - main - DEBUG - Batch 1000: running loss = 711144.5614
2022-12-30 14:32:22,777 - main - INFO - Epoch 35 - train: epoch loss = 709.5635
2022-12-30 14:32:22,778 - main - INFO - validating...
2022-12-30 14:39:15,552 - main - DEBUG - Batch 500: running loss = 300967.0649
2022-12-30 14:39:21,317 - main - INFO - Epoch 35 - val: epoch loss = 602.0734
2022-12-30 14:39:21,486 - main - INFO - Saved the best model at epoch 35.
2022-12-30 14:39:21,487 - main - INFO - Epoch 36/5000
2022-12-30 14:39:21,487 - main - INFO - ----------------------------
2022-12-30 14:39:21,488 - main - INFO - training...
2022-12-30 14:48:37,958 - main - DEBUG - Batch 500: running loss = 351593.1349
2022-12-30 14:58:30,077 - main - DEBUG - Batch 1000: running loss = 701509.9876
2022-12-30 15:07:59,607 - main - INFO - Epoch 36 - train: epoch loss = 699.0265
2022-12-30 15:07:59,608 - main - INFO - validating...
2022-12-30 15:15:18,401 - main - DEBUG - Batch 500: running loss = 292602.0063
2022-12-30 15:15:24,613 - main - INFO - Epoch 36 - val: epoch loss = 585.3660
2022-12-30 15:15:24,799 - main - INFO - Saved the best model at epoch 36.
2022-12-30 15:15:24,800 - main - INFO - Epoch 37/5000
2022-12-30 15:15:24,801 - main - INFO - ----------------------------
2022-12-30 15:15:24,801 - main - INFO - training...
2022-12-30 15:25:20,036 - main - DEBUG - Batch 500: running loss = 346182.0858
2022-12-30 15:35:16,103 - main - DEBUG - Batch 1000: running loss = 690974.2305
2022-12-30 15:44:43,683 - main - INFO - Epoch 37 - train: epoch loss = 689.1659
2022-12-30 15:44:43,684 - main - INFO - validating...
2022-12-30 15:51:57,134 - main - DEBUG - Batch 500: running loss = 288578.2544
2022-12-30 15:52:03,151 - main - INFO - Epoch 37 - val: epoch loss = 577.2947
2022-12-30 15:52:03,363 - main - INFO - Saved the best model at epoch 37.
2022-12-30 15:52:03,364 - main - INFO - Epoch 38/5000
2022-12-30 15:52:03,365 - main - INFO - ----------------------------
2022-12-30 15:52:03,366 - main - INFO - training...
2022-12-30 16:01:56,053 - main - DEBUG - Batch 500: running loss = 341288.8401
2022-12-30 16:11:44,236 - main - DEBUG - Batch 1000: running loss = 680992.0280
2022-12-30 16:20:34,650 - main - INFO - Epoch 38 - train: epoch loss = 679.7061
2022-12-30 16:20:34,651 - main - INFO - validating...
2022-12-30 16:27:27,219 - main - DEBUG - Batch 500: running loss = 283870.4673
2022-12-30 16:27:32,973 - main - INFO - Epoch 38 - val: epoch loss = 567.8505
2022-12-30 16:27:33,139 - main - INFO - Saved the best model at epoch 38.
2022-12-30 16:27:33,140 - main - INFO - Epoch 39/5000
2022-12-30 16:27:33,140 - main - INFO - ----------------------------
2022-12-30 16:27:33,141 - main - INFO - training...
2022-12-30 16:36:47,383 - main - DEBUG - Batch 500: running loss = 336823.9150
2022-12-30 16:46:02,339 - main - DEBUG - Batch 1000: running loss = 671875.4312
2022-12-30 16:54:52,725 - main - INFO - Epoch 39 - train: epoch loss = 670.9318
2022-12-30 16:54:52,726 - main - INFO - validating...
2022-12-30 17:01:58,636 - main - DEBUG - Batch 500: running loss = 278398.8127
2022-12-30 17:02:04,836 - main - INFO - Epoch 39 - val: epoch loss = 556.9123
2022-12-30 17:02:05,026 - main - INFO - Saved the best model at epoch 39.
2022-12-30 17:02:05,027 - main - INFO - Epoch 40/5000
2022-12-30 17:02:05,027 - main - INFO - ----------------------------
2022-12-30 17:02:05,028 - main - INFO - training...
2022-12-30 17:11:29,783 - main - DEBUG - Batch 500: running loss = 331671.7769
2022-12-30 17:20:44,860 - main - DEBUG - Batch 1000: running loss = 663047.6557
2022-12-30 17:29:39,632 - main - INFO - Epoch 40 - train: epoch loss = 662.3694
2022-12-30 17:29:39,633 - main - INFO - validating...
2022-12-30 17:36:32,091 - main - DEBUG - Batch 500: running loss = 272184.4225
2022-12-30 17:36:37,838 - main - INFO - Epoch 40 - val: epoch loss = 544.4598
2022-12-30 17:36:37,995 - main - INFO - Saved the best model at epoch 40.
2022-12-30 17:36:37,996 - main - INFO - Epoch 41/5000
2022-12-30 17:36:37,996 - main - INFO - ----------------------------
2022-12-30 17:36:37,998 - main - INFO - training...
2022-12-30 17:46:01,203 - main - DEBUG - Batch 500: running loss = 327853.8215
2022-12-30 17:55:27,513 - main - DEBUG - Batch 1000: running loss = 656674.5682
2022-12-30 18:04:24,588 - main - INFO - Epoch 41 - train: epoch loss = 654.4109
2022-12-30 18:04:24,589 - main - INFO - validating...
2022-12-30 18:11:16,519 - main - DEBUG - Batch 500: running loss = 268352.6637
2022-12-30 18:11:22,263 - main - INFO - Epoch 41 - val: epoch loss = 536.8123
2022-12-30 18:11:22,432 - main - INFO - Saved the best model at epoch 41.
2022-12-30 18:11:22,433 - main - INFO - Epoch 42/5000
2022-12-30 18:11:22,433 - main - INFO - ----------------------------
2022-12-30 18:11:22,434 - main - INFO - training...
2022-12-30 18:20:36,887 - main - DEBUG - Batch 500: running loss = 324533.5595
2022-12-30 18:29:52,036 - main - DEBUG - Batch 1000: running loss = 646842.4030
2022-12-30 18:38:42,344 - main - INFO - Epoch 42 - train: epoch loss = 646.8434
2022-12-30 18:38:42,345 - main - INFO - validating...
2022-12-30 18:45:33,784 - main - DEBUG - Batch 500: running loss = 265220.5332
2022-12-30 18:45:39,523 - main - INFO - Epoch 42 - val: epoch loss = 530.5339
2022-12-30 18:45:39,689 - main - INFO - Saved the best model at epoch 42.
2022-12-30 18:45:39,689 - main - INFO - Epoch 43/5000
2022-12-30 18:45:39,690 - main - INFO - ----------------------------
2022-12-30 18:45:39,690 - main - INFO - training...
2022-12-30 18:54:52,511 - main - DEBUG - Batch 500: running loss = 322294.8017
2022-12-30 19:04:05,742 - main - DEBUG - Batch 1000: running loss = 641645.5599
2022-12-30 19:12:55,285 - main - INFO - Epoch 43 - train: epoch loss = 639.6605
2022-12-30 19:12:55,285 - main - INFO - validating...
2022-12-30 19:19:45,964 - main - DEBUG - Batch 500: running loss = 262592.5573
2022-12-30 19:19:51,693 - main - INFO - Epoch 43 - val: epoch loss = 525.2708
2022-12-30 19:19:51,858 - main - INFO - Saved the best model at epoch 43.
2022-12-30 19:19:51,858 - main - INFO - Epoch 44/5000
2022-12-30 19:19:51,859 - main - INFO - ----------------------------
2022-12-30 19:19:51,859 - main - INFO - training...
2022-12-30 19:29:05,737 - main - DEBUG - Batch 500: running loss = 315907.9233
2022-12-30 19:38:19,997 - main - DEBUG - Batch 1000: running loss = 632312.9175
2022-12-30 19:47:09,195 - main - INFO - Epoch 44 - train: epoch loss = 632.6299
2022-12-30 19:47:09,196 - main - INFO - validating...
2022-12-30 19:53:59,813 - main - DEBUG - Batch 500: running loss = 256149.0494
2022-12-30 19:54:05,552 - main - INFO - Epoch 44 - val: epoch loss = 512.3587
2022-12-30 19:54:05,718 - main - INFO - Saved the best model at epoch 44.
2022-12-30 19:54:05,718 - main - INFO - Epoch 45/5000
2022-12-30 19:54:05,718 - main - INFO - ----------------------------
2022-12-30 19:54:05,719 - main - INFO - training...
2022-12-30 20:03:18,163 - main - DEBUG - Batch 500: running loss = 314153.3820
2022-12-30 20:12:31,946 - main - DEBUG - Batch 1000: running loss = 628163.5201
2022-12-30 20:21:21,582 - main - INFO - Epoch 45 - train: epoch loss = 626.1749
2022-12-30 20:21:21,582 - main - INFO - validating...
2022-12-30 20:28:12,556 - main - DEBUG - Batch 500: running loss = 253521.7687
2022-12-30 20:28:18,294 - main - INFO - Epoch 45 - val: epoch loss = 507.1587
2022-12-30 20:28:18,460 - main - INFO - Saved the best model at epoch 45.
2022-12-30 20:28:18,461 - main - INFO - Epoch 46/5000
2022-12-30 20:28:18,461 - main - INFO - ----------------------------
2022-12-30 20:28:18,462 - main - INFO - training...
2022-12-30 20:37:31,681 - main - DEBUG - Batch 500: running loss = 312383.1130
2022-12-30 20:46:45,190 - main - DEBUG - Batch 1000: running loss = 622234.0608
2022-12-30 20:55:34,167 - main - INFO - Epoch 46 - train: epoch loss = 619.8703
2022-12-30 20:55:34,167 - main - INFO - validating...
2022-12-30 21:02:24,866 - main - DEBUG - Batch 500: running loss = 248517.4220
2022-12-30 21:02:30,589 - main - INFO - Epoch 46 - val: epoch loss = 497.1274
2022-12-30 21:02:30,758 - main - INFO - Saved the best model at epoch 46.
2022-12-30 21:02:30,758 - main - INFO - Epoch 47/5000
2022-12-30 21:02:30,759 - main - INFO - ----------------------------
2022-12-30 21:02:30,760 - main - INFO - training...
2022-12-30 21:11:43,760 - main - DEBUG - Batch 500: running loss = 307920.4977
2022-12-30 21:20:57,552 - main - DEBUG - Batch 1000: running loss = 614284.0843
2022-12-30 21:29:47,114 - main - INFO - Epoch 47 - train: epoch loss = 613.9485
2022-12-30 21:29:47,114 - main - INFO - validating...
2022-12-30 21:36:37,701 - main - DEBUG - Batch 500: running loss = 247990.5609
2022-12-30 21:36:43,414 - main - INFO - Epoch 47 - val: epoch loss = 496.0810
2022-12-30 21:36:43,586 - main - INFO - Saved the best model at epoch 47.
2022-12-30 21:36:43,586 - main - INFO - Epoch 48/5000
2022-12-30 21:36:43,587 - main - INFO - ----------------------------
2022-12-30 21:36:43,588 - main - INFO - training...
2022-12-30 21:45:55,542 - main - DEBUG - Batch 500: running loss = 305733.9130
2022-12-30 21:55:07,915 - main - DEBUG - Batch 1000: running loss = 608689.6167
2022-12-30 22:03:56,168 - main - INFO - Epoch 48 - train: epoch loss = 608.1772
2022-12-30 22:03:56,169 - main - INFO - validating...
2022-12-30 22:10:46,848 - main - DEBUG - Batch 500: running loss = 244997.4481
2022-12-30 22:10:52,580 - main - INFO - Epoch 48 - val: epoch loss = 490.0714
2022-12-30 22:10:52,745 - main - INFO - Saved the best model at epoch 48.
2022-12-30 22:10:52,745 - main - INFO - Epoch 49/5000
2022-12-30 22:10:52,746 - main - INFO - ----------------------------
2022-12-30 22:10:52,746 - main - INFO - training...
2022-12-30 22:20:05,958 - main - DEBUG - Batch 500: running loss = 301464.3287
2022-12-30 22:29:19,944 - main - DEBUG - Batch 1000: running loss = 604834.8080
2022-12-30 22:38:08,962 - main - INFO - Epoch 49 - train: epoch loss = 602.5877
2022-12-30 22:38:08,963 - main - INFO - validating...
2022-12-30 22:44:59,551 - main - DEBUG - Batch 500: running loss = 240353.4421
2022-12-30 22:45:05,290 - main - INFO - Epoch 49 - val: epoch loss = 480.7819
2022-12-30 22:45:05,457 - main - INFO - Saved the best model at epoch 49.
2022-12-30 22:45:05,458 - main - INFO - Epoch 50/5000
2022-12-30 22:45:05,458 - main - INFO - ----------------------------
2022-12-30 22:45:05,459 - main - INFO - training...
2022-12-30 22:54:17,815 - main - DEBUG - Batch 500: running loss = 300752.0266
2022-12-30 23:03:30,984 - main - DEBUG - Batch 1000: running loss = 599083.5846
2022-12-30 23:12:20,297 - main - INFO - Epoch 50 - train: epoch loss = 597.4051
2022-12-30 23:12:20,298 - main - INFO - validating...
2022-12-30 23:19:10,936 - main - DEBUG - Batch 500: running loss = 237068.1214
2022-12-30 23:19:16,658 - main - INFO - Epoch 50 - val: epoch loss = 474.2246
2022-12-30 23:19:16,824 - main - INFO - Saved the best model at epoch 50.
2022-12-30 23:19:16,825 - main - INFO - Epoch 51/5000
2022-12-30 23:19:16,825 - main - INFO - ----------------------------
2022-12-30 23:19:16,826 - main - INFO - training...
2022-12-30 23:28:29,935 - main - DEBUG - Batch 500: running loss = 296400.2675
2022-12-30 23:37:43,230 - main - DEBUG - Batch 1000: running loss = 593436.0164
2022-12-30 23:46:31,939 - main - INFO - Epoch 51 - train: epoch loss = 592.4150
2022-12-30 23:46:31,940 - main - INFO - validating...
2022-12-30 23:53:22,427 - main - DEBUG - Batch 500: running loss = 236214.4427
2022-12-30 23:53:28,134 - main - INFO - Epoch 51 - val: epoch loss = 472.4980
2022-12-30 23:53:28,306 - main - INFO - Saved the best model at epoch 51.
2022-12-30 23:53:28,306 - main - INFO - Epoch 52/5000
2022-12-30 23:53:28,306 - main - INFO - ----------------------------
2022-12-30 23:53:28,307 - main - INFO - training...
2022-12-31 00:02:40,607 - main - DEBUG - Batch 500: running loss = 294229.2410
2022-12-31 00:11:54,289 - main - DEBUG - Batch 1000: running loss = 587972.8527
2022-12-31 00:20:43,553 - main - INFO - Epoch 52 - train: epoch loss = 587.5397
2022-12-31 00:20:43,554 - main - INFO - validating...
2022-12-31 00:27:34,121 - main - DEBUG - Batch 500: running loss = 232274.2820
2022-12-31 00:27:39,855 - main - INFO - Epoch 52 - val: epoch loss = 464.6063
2022-12-31 00:27:40,018 - main - INFO - Saved the best model at epoch 52.
2022-12-31 00:27:40,019 - main - INFO - Epoch 53/5000
2022-12-31 00:27:40,019 - main - INFO - ----------------------------
2022-12-31 00:27:40,020 - main - INFO - training...
2022-12-31 00:36:52,764 - main - DEBUG - Batch 500: running loss = 291732.7937
2022-12-31 00:46:05,946 - main - DEBUG - Batch 1000: running loss = 584090.1064
2022-12-31 00:54:54,607 - main - INFO - Epoch 53 - train: epoch loss = 582.9227
2022-12-31 00:54:54,608 - main - INFO - validating...
2022-12-31 01:01:44,969 - main - DEBUG - Batch 500: running loss = 229713.6021
2022-12-31 01:01:50,700 - main - INFO - Epoch 53 - val: epoch loss = 459.4966
2022-12-31 01:01:50,865 - main - INFO - Saved the best model at epoch 53.
2022-12-31 01:01:50,866 - main - INFO - Epoch 54/5000
2022-12-31 01:01:50,866 - main - INFO - ----------------------------
2022-12-31 01:01:50,868 - main - INFO - training...
2022-12-31 01:11:03,820 - main - DEBUG - Batch 500: running loss = 290922.8651
2022-12-31 01:20:17,599 - main - DEBUG - Batch 1000: running loss = 579962.2002
2022-12-31 01:29:06,778 - main - INFO - Epoch 54 - train: epoch loss = 578.5704
2022-12-31 01:29:06,779 - main - INFO - validating...
2022-12-31 01:35:57,330 - main - DEBUG - Batch 500: running loss = 227989.7563
2022-12-31 01:36:03,053 - main - INFO - Epoch 54 - val: epoch loss = 456.0483
2022-12-31 01:36:03,217 - main - INFO - Saved the best model at epoch 54.
2022-12-31 01:36:03,218 - main - INFO - Epoch 55/5000
2022-12-31 01:36:03,219 - main - INFO - ----------------------------
2022-12-31 01:36:03,220 - main - INFO - training...
2022-12-31 01:45:14,882 - main - DEBUG - Batch 500: running loss = 288125.8532
2022-12-31 01:54:26,993 - main - DEBUG - Batch 1000: running loss = 575029.1012
2022-12-31 02:03:15,772 - main - INFO - Epoch 55 - train: epoch loss = 574.2430
2022-12-31 02:03:15,773 - main - INFO - validating...
2022-12-31 02:10:06,468 - main - DEBUG - Batch 500: running loss = 225786.9325
2022-12-31 02:10:12,188 - main - INFO - Epoch 55 - val: epoch loss = 451.6443
2022-12-31 02:10:12,355 - main - INFO - Saved the best model at epoch 55.
2022-12-31 02:10:12,356 - main - INFO - Epoch 56/5000
2022-12-31 02:10:12,356 - main - INFO - ----------------------------
2022-12-31 02:10:12,357 - main - INFO - training...
2022-12-31 02:19:25,384 - main - DEBUG - Batch 500: running loss = 285954.2281
2022-12-31 02:28:38,884 - main - DEBUG - Batch 1000: running loss = 570710.7654
2022-12-31 02:37:27,637 - main - INFO - Epoch 56 - train: epoch loss = 570.1851
2022-12-31 02:37:27,638 - main - INFO - validating...
2022-12-31 02:44:17,851 - main - DEBUG - Batch 500: running loss = 222595.0865
2022-12-31 02:44:23,573 - main - INFO - Epoch 56 - val: epoch loss = 445.2519
2022-12-31 02:44:23,738 - main - INFO - Saved the best model at epoch 56.
2022-12-31 02:44:23,738 - main - INFO - Epoch 57/5000
2022-12-31 02:44:23,739 - main - INFO - ----------------------------
2022-12-31 02:44:23,739 - main - INFO - training...
2022-12-31 02:53:35,275 - main - DEBUG - Batch 500: running loss = 284500.4144
2022-12-31 03:02:48,718 - main - DEBUG - Batch 1000: running loss = 567381.2358
2022-12-31 03:11:37,956 - main - INFO - Epoch 57 - train: epoch loss = 566.2569
2022-12-31 03:11:37,957 - main - INFO - validating...
2022-12-31 03:18:28,563 - main - DEBUG - Batch 500: running loss = 220997.0688
2022-12-31 03:18:34,278 - main - INFO - Epoch 57 - val: epoch loss = 442.0717
2022-12-31 03:18:34,444 - main - INFO - Saved the best model at epoch 57.
2022-12-31 03:18:34,445 - main - INFO - Epoch 58/5000
2022-12-31 03:18:34,445 - main - INFO - ----------------------------
2022-12-31 03:18:34,446 - main - INFO - training...
2022-12-31 03:27:47,260 - main - DEBUG - Batch 500: running loss = 282975.4778
2022-12-31 03:37:00,423 - main - DEBUG - Batch 1000: running loss = 564037.1786
2022-12-31 03:45:49,055 - main - INFO - Epoch 58 - train: epoch loss = 562.4855
2022-12-31 03:45:49,056 - main - INFO - validating...
2022-12-31 03:52:39,336 - main - DEBUG - Batch 500: running loss = 220097.6657
2022-12-31 03:52:45,049 - main - INFO - Epoch 58 - val: epoch loss = 440.2676
2022-12-31 03:52:45,215 - main - INFO - Saved the best model at epoch 58.
2022-12-31 03:52:45,216 - main - INFO - Epoch 59/5000
2022-12-31 03:52:45,217 - main - INFO - ----------------------------
2022-12-31 03:52:45,218 - main - INFO - training...
2022-12-31 04:01:57,815 - main - DEBUG - Batch 500: running loss = 281083.1709
2022-12-31 04:11:11,473 - main - DEBUG - Batch 1000: running loss = 559632.2421
2022-12-31 04:20:00,687 - main - INFO - Epoch 59 - train: epoch loss = 558.7338
2022-12-31 04:20:00,688 - main - INFO - validating...
2022-12-31 04:26:51,354 - main - DEBUG - Batch 500: running loss = 218496.4015
2022-12-31 04:26:57,085 - main - INFO - Epoch 59 - val: epoch loss = 437.0476
2022-12-31 04:26:57,251 - main - INFO - Saved the best model at epoch 59.
2022-12-31 04:26:57,252 - main - INFO - Epoch 60/5000
2022-12-31 04:26:57,252 - main - INFO - ----------------------------
2022-12-31 04:26:57,253 - main - INFO - training...
2022-12-31 04:36:08,918 - main - DEBUG - Batch 500: running loss = 278263.9564
2022-12-31 04:45:21,051 - main - DEBUG - Batch 1000: running loss = 555723.3278
2022-12-31 04:54:08,941 - main - INFO - Epoch 60 - train: epoch loss = 555.1515
2022-12-31 04:54:08,942 - main - INFO - validating...
2022-12-31 05:00:59,396 - main - DEBUG - Batch 500: running loss = 215459.2250
2022-12-31 05:01:05,121 - main - INFO - Epoch 60 - val: epoch loss = 430.9867
2022-12-31 05:01:05,286 - main - INFO - Saved the best model at epoch 60.
2022-12-31 05:01:05,287 - main - INFO - Epoch 61/5000
2022-12-31 05:01:05,288 - main - INFO - ----------------------------
2022-12-31 05:01:05,289 - main - INFO - training...
2022-12-31 05:10:18,072 - main - DEBUG - Batch 500: running loss = 277160.8734
2022-12-31 05:19:31,778 - main - DEBUG - Batch 1000: running loss = 550529.7380
2022-12-31 05:28:20,551 - main - INFO - Epoch 61 - train: epoch loss = 551.9076
2022-12-31 05:28:20,557 - main - INFO - validating...
2022-12-31 05:35:11,098 - main - DEBUG - Batch 500: running loss = 212532.1159
2022-12-31 05:35:16,816 - main - INFO - Epoch 61 - val: epoch loss = 425.1292
2022-12-31 05:35:16,984 - main - INFO - Saved the best model at epoch 61.
2022-12-31 05:35:16,985 - main - INFO - Epoch 62/5000
2022-12-31 05:35:16,985 - main - INFO - ----------------------------
2022-12-31 05:35:16,986 - main - INFO - training...
2022-12-31 05:44:28,495 - main - DEBUG - Batch 500: running loss = 275272.6778
2022-12-31 05:53:40,902 - main - DEBUG - Batch 1000: running loss = 548965.1432
2022-12-31 06:02:30,004 - main - INFO - Epoch 62 - train: epoch loss = 548.5620
2022-12-31 06:02:30,005 - main - INFO - validating...
2022-12-31 06:09:20,614 - main - DEBUG - Batch 500: running loss = 210509.6907
2022-12-31 06:09:26,340 - main - INFO - Epoch 62 - val: epoch loss = 421.0697
2022-12-31 06:09:26,504 - main - INFO - Saved the best model at epoch 62.
2022-12-31 06:09:26,505 - main - INFO - Epoch 63/5000
2022-12-31 06:09:26,506 - main - INFO - ----------------------------
2022-12-31 06:09:26,506 - main - INFO - training...
2022-12-31 06:18:39,439 - main - DEBUG - Batch 500: running loss = 273451.2696
2022-12-31 06:27:52,818 - main - DEBUG - Batch 1000: running loss = 545937.7088
2022-12-31 06:36:41,434 - main - INFO - Epoch 63 - train: epoch loss = 545.4492
2022-12-31 06:36:41,435 - main - INFO - validating...
2022-12-31 06:43:31,894 - main - DEBUG - Batch 500: running loss = 208898.1443
2022-12-31 06:43:37,605 - main - INFO - Epoch 63 - val: epoch loss = 417.8397
2022-12-31 06:43:37,778 - main - INFO - Saved the best model at epoch 63.
2022-12-31 06:43:37,778 - main - INFO - Epoch 64/5000
2022-12-31 06:43:37,779 - main - INFO - ----------------------------
2022-12-31 06:43:37,780 - main - INFO - training...
2022-12-31 06:52:49,605 - main - DEBUG - Batch 500: running loss = 272930.3071
2022-12-31 07:02:03,144 - main - DEBUG - Batch 1000: running loss = 544022.0387
2022-12-31 07:10:52,311 - main - INFO - Epoch 64 - train: epoch loss = 542.3766
2022-12-31 07:10:52,311 - main - INFO - validating...
2022-12-31 07:17:43,123 - main - DEBUG - Batch 500: running loss = 207657.6786
2022-12-31 07:17:48,833 - main - INFO - Epoch 64 - val: epoch loss = 415.3785
2022-12-31 07:17:48,998 - main - INFO - Saved the best model at epoch 64.
2022-12-31 07:17:48,999 - main - INFO - Epoch 65/5000
2022-12-31 07:17:48,999 - main - INFO - ----------------------------
2022-12-31 07:17:49,000 - main - INFO - training...
2022-12-31 07:27:00,786 - main - DEBUG - Batch 500: running loss = 270831.9831
2022-12-31 07:36:12,953 - main - DEBUG - Batch 1000: running loss = 539078.5964
2022-12-31 07:45:00,619 - main - INFO - Epoch 65 - train: epoch loss = 539.3641
2022-12-31 07:45:00,620 - main - INFO - validating...
2022-12-31 07:51:51,219 - main - DEBUG - Batch 500: running loss = 205353.3170
2022-12-31 07:51:56,945 - main - INFO - Epoch 65 - val: epoch loss = 410.7844
2022-12-31 07:51:57,110 - main - INFO - Saved the best model at epoch 65.
2022-12-31 07:51:57,110 - main - INFO - Epoch 66/5000
2022-12-31 07:51:57,111 - main - INFO - ----------------------------
2022-12-31 07:51:57,112 - main - INFO - training...
2022-12-31 08:01:09,880 - main - DEBUG - Batch 500: running loss = 270496.0180
2022-12-31 08:10:23,516 - main - DEBUG - Batch 1000: running loss = 538297.1894
2022-12-31 08:19:12,596 - main - INFO - Epoch 66 - train: epoch loss = 536.5017
2022-12-31 08:19:12,597 - main - INFO - validating...
2022-12-31 08:26:03,105 - main - DEBUG - Batch 500: running loss = 204164.5110
2022-12-31 08:26:08,822 - main - INFO - Epoch 66 - val: epoch loss = 408.3885
2022-12-31 08:26:08,988 - main - INFO - Saved the best model at epoch 66.
2022-12-31 08:26:08,989 - main - INFO - Epoch 67/5000
2022-12-31 08:26:08,989 - main - INFO - ----------------------------
2022-12-31 08:26:08,990 - main - INFO - training...
2022-12-31 08:35:20,663 - main - DEBUG - Batch 500: running loss = 268814.4509
2022-12-31 08:44:32,826 - main - DEBUG - Batch 1000: running loss = 533944.2564
2022-12-31 08:53:21,488 - main - INFO - Epoch 67 - train: epoch loss = 533.8479
2022-12-31 08:53:21,488 - main - INFO - validating...
2022-12-31 09:00:12,201 - main - DEBUG - Batch 500: running loss = 204056.7336
2022-12-31 09:00:17,931 - main - INFO - Epoch 67 - val: epoch loss = 408.1585
2022-12-31 09:00:18,097 - main - INFO - Saved the best model at epoch 67.
2022-12-31 09:00:18,097 - main - INFO - Epoch 68/5000
2022-12-31 09:00:18,098 - main - INFO - ----------------------------
2022-12-31 09:00:18,098 - main - INFO - training...
2022-12-31 09:09:31,163 - main - DEBUG - Batch 500: running loss = 265255.2132
2022-12-31 09:18:44,796 - main - DEBUG - Batch 1000: running loss = 531340.5902
2022-12-31 09:27:33,617 - main - INFO - Epoch 68 - train: epoch loss = 531.2226
2022-12-31 09:27:33,617 - main - INFO - validating...
2022-12-31 09:34:24,232 - main - DEBUG - Batch 500: running loss = 201921.5808
2022-12-31 09:34:29,959 - main - INFO - Epoch 68 - val: epoch loss = 403.8953
2022-12-31 09:34:30,124 - main - INFO - Saved the best model at epoch 68.
2022-12-31 09:34:30,124 - main - INFO - Epoch 69/5000
2022-12-31 09:34:30,125 - main - INFO - ----------------------------
2022-12-31 09:34:30,125 - main - INFO - training...
2022-12-31 09:43:41,748 - main - DEBUG - Batch 500: running loss = 264123.3534
2022-12-31 09:52:54,865 - main - DEBUG - Batch 1000: running loss = 527858.7231
2022-12-31 10:01:44,100 - main - INFO - Epoch 69 - train: epoch loss = 528.5427
2022-12-31 10:01:44,101 - main - INFO - validating...
2022-12-31 10:08:35,022 - main - DEBUG - Batch 500: running loss = 200084.9862
2022-12-31 10:08:40,746 - main - INFO - Epoch 69 - val: epoch loss = 400.2162
2022-12-31 10:08:40,910 - main - INFO - Saved the best model at epoch 69.
2022-12-31 10:08:40,910 - main - INFO - Epoch 70/5000
2022-12-31 10:08:40,911 - main - INFO - ----------------------------
2022-12-31 10:08:40,912 - main - INFO - training...
2022-12-31 10:17:53,893 - main - DEBUG - Batch 500: running loss = 263095.5985
2022-12-31 10:27:07,172 - main - DEBUG - Batch 1000: running loss = 526079.6690
2022-12-31 10:35:55,894 - main - INFO - Epoch 70 - train: epoch loss = 526.1067
2022-12-31 10:35:55,895 - main - INFO - validating...
2022-12-31 10:42:46,774 - main - DEBUG - Batch 500: running loss = 198662.1439
2022-12-31 10:42:52,508 - main - INFO - Epoch 70 - val: epoch loss = 397.3660
2022-12-31 10:42:52,673 - main - INFO - Saved the best model at epoch 70.
2022-12-31 10:42:52,673 - main - INFO - Epoch 71/5000
2022-12-31 10:42:52,674 - main - INFO - ----------------------------
2022-12-31 10:42:52,674 - main - INFO - training...
2022-12-31 10:52:05,281 - main - DEBUG - Batch 500: running loss = 260716.2399
2022-12-31 11:01:18,939 - main - DEBUG - Batch 1000: running loss = 522853.0901
2022-12-31 11:10:08,205 - main - INFO - Epoch 71 - train: epoch loss = 523.6864
2022-12-31 11:10:08,206 - main - INFO - validating...
2022-12-31 11:16:58,974 - main - DEBUG - Batch 500: running loss = 195504.1863
2022-12-31 11:17:04,701 - main - INFO - Epoch 71 - val: epoch loss = 391.0547
2022-12-31 11:17:04,867 - main - INFO - Saved the best model at epoch 71.
2022-12-31 11:17:04,868 - main - INFO - Epoch 72/5000
2022-12-31 11:17:04,868 - main - INFO - ----------------------------
2022-12-31 11:17:04,869 - main - INFO - training...
2022-12-31 11:26:17,301 - main - DEBUG - Batch 500: running loss = 259867.6489
2022-12-31 11:35:30,425 - main - DEBUG - Batch 1000: running loss = 520184.9669
2022-12-31 11:44:19,136 - main - INFO - Epoch 72 - train: epoch loss = 521.3242
2022-12-31 11:44:19,137 - main - INFO - validating...
2022-12-31 11:51:09,909 - main - DEBUG - Batch 500: running loss = 194572.7836
2022-12-31 11:51:15,622 - main - INFO - Epoch 72 - val: epoch loss = 389.1650
2022-12-31 11:51:15,788 - main - INFO - Saved the best model at epoch 72.
2022-12-31 11:51:15,789 - main - INFO - Epoch 73/5000
2022-12-31 11:51:15,789 - main - INFO - ----------------------------
2022-12-31 11:51:15,790 - main - INFO - training...
2022-12-31 12:00:28,774 - main - DEBUG - Batch 500: running loss = 258344.8889
2022-12-31 12:09:42,538 - main - DEBUG - Batch 1000: running loss = 519823.7783
2022-12-31 12:18:31,482 - main - INFO - Epoch 73 - train: epoch loss = 519.1485
2022-12-31 12:18:31,483 - main - INFO - validating...
2022-12-31 12:25:21,940 - main - DEBUG - Batch 500: running loss = 193655.3355
2022-12-31 12:25:27,659 - main - INFO - Epoch 73 - val: epoch loss = 387.3476
2022-12-31 12:25:27,824 - main - INFO - Saved the best model at epoch 73.
2022-12-31 12:25:27,824 - main - INFO - Epoch 74/5000
2022-12-31 12:25:27,825 - main - INFO - ----------------------------
2022-12-31 12:25:27,825 - main - INFO - training...
2022-12-31 12:34:39,930 - main - DEBUG - Batch 500: running loss = 257161.0368
2022-12-31 12:43:53,126 - main - DEBUG - Batch 1000: running loss = 516557.2488
2022-12-31 12:52:42,159 - main - INFO - Epoch 74 - train: epoch loss = 516.7322
2022-12-31 12:52:42,160 - main - INFO - validating...
2022-12-31 12:59:32,946 - main - DEBUG - Batch 500: running loss = 193903.8318
2022-12-31 12:59:38,683 - main - INFO - Epoch 74 - val: epoch loss = 387.8312
2022-12-31 12:59:38,684 - main - INFO - Epoch 75/5000
2022-12-31 12:59:38,684 - main - INFO - ----------------------------
2022-12-31 12:59:38,685 - main - INFO - training...
2022-12-31 13:08:51,788 - main - DEBUG - Batch 500: running loss = 257106.0851
2022-12-31 13:18:05,115 - main - DEBUG - Batch 1000: running loss = 514898.4125
2022-12-31 13:26:53,756 - main - INFO - Epoch 75 - train: epoch loss = 514.7890
2022-12-31 13:26:53,757 - main - INFO - validating...
2022-12-31 13:33:44,154 - main - DEBUG - Batch 500: running loss = 191303.3361
2022-12-31 13:33:49,877 - main - INFO - Epoch 75 - val: epoch loss = 382.6404
2022-12-31 13:33:50,041 - main - INFO - Saved the best model at epoch 75.
2022-12-31 13:33:50,042 - main - INFO - Epoch 76/5000
2022-12-31 13:33:50,042 - main - INFO - ----------------------------
2022-12-31 13:33:50,043 - main - INFO - training...
2022-12-31 13:43:02,036 - main - DEBUG - Batch 500: running loss = 255565.9651
2022-12-31 13:52:15,571 - main - DEBUG - Batch 1000: running loss = 512649.8709
2022-12-31 14:01:04,797 - main - INFO - Epoch 76 - train: epoch loss = 512.6268
2022-12-31 14:01:04,798 - main - INFO - validating...
2022-12-31 14:07:55,605 - main - DEBUG - Batch 500: running loss = 190403.8227
2022-12-31 14:08:01,324 - main - INFO - Epoch 76 - val: epoch loss = 380.8370
2022-12-31 14:08:01,498 - main - INFO - Saved the best model at epoch 76.
2022-12-31 14:08:01,499 - main - INFO - Epoch 77/5000
2022-12-31 14:08:01,500 - main - INFO - ----------------------------
2022-12-31 14:08:01,500 - main - INFO - training...
2022-12-31 14:17:14,137 - main - DEBUG - Batch 500: running loss = 255685.6218
2022-12-31 14:26:27,223 - main - DEBUG - Batch 1000: running loss = 510162.3143
2022-12-31 14:35:15,827 - main - INFO - Epoch 77 - train: epoch loss = 510.5582
2022-12-31 14:35:15,828 - main - INFO - validating...
2022-12-31 14:42:06,349 - main - DEBUG - Batch 500: running loss = 190098.9002
2022-12-31 14:42:12,073 - main - INFO - Epoch 77 - val: epoch loss = 380.2310
2022-12-31 14:42:12,240 - main - INFO - Saved the best model at epoch 77.
2022-12-31 14:42:12,241 - main - INFO - Epoch 78/5000
2022-12-31 14:42:12,241 - main - INFO - ----------------------------
2022-12-31 14:42:12,242 - main - INFO - training...
2022-12-31 14:51:25,028 - main - DEBUG - Batch 500: running loss = 254693.7252
2022-12-31 15:00:38,697 - main - DEBUG - Batch 1000: running loss = 508119.3425
2022-12-31 15:09:27,858 - main - INFO - Epoch 78 - train: epoch loss = 508.6375
2022-12-31 15:09:27,859 - main - INFO - validating...
2022-12-31 15:16:18,268 - main - DEBUG - Batch 500: running loss = 189070.7729
2022-12-31 15:16:23,996 - main - INFO - Epoch 78 - val: epoch loss = 378.1574
2022-12-31 15:16:24,161 - main - INFO - Saved the best model at epoch 78.
2022-12-31 15:16:24,162 - main - INFO - Epoch 79/5000
2022-12-31 15:16:24,162 - main - INFO - ----------------------------
2022-12-31 15:16:24,163 - main - INFO - training...
2022-12-31 15:25:36,368 - main - DEBUG - Batch 500: running loss = 253218.5822
2022-12-31 15:34:49,424 - main - DEBUG - Batch 1000: running loss = 506732.2986
2022-12-31 15:43:38,307 - main - INFO - Epoch 79 - train: epoch loss = 506.7051
2022-12-31 15:43:38,308 - main - INFO - validating...
2022-12-31 15:50:28,893 - main - DEBUG - Batch 500: running loss = 187718.0974
2022-12-31 15:50:34,621 - main - INFO - Epoch 79 - val: epoch loss = 375.4627
2022-12-31 15:50:34,784 - main - INFO - Saved the best model at epoch 79.
2022-12-31 15:50:34,784 - main - INFO - Epoch 80/5000
2022-12-31 15:50:34,785 - main - INFO - ----------------------------
2022-12-31 15:50:34,785 - main - INFO - training...
2022-12-31 15:59:47,843 - main - DEBUG - Batch 500: running loss = 253890.0253
2022-12-31 16:09:01,454 - main - DEBUG - Batch 1000: running loss = 505137.8394
2022-12-31 16:17:50,230 - main - INFO - Epoch 80 - train: epoch loss = 504.8990
2022-12-31 16:17:50,231 - main - INFO - validating...
2022-12-31 16:24:40,577 - main - DEBUG - Batch 500: running loss = 186080.5159
2022-12-31 16:24:46,303 - main - INFO - Epoch 80 - val: epoch loss = 372.1845
2022-12-31 16:24:46,466 - main - INFO - Saved the best model at epoch 80.
2022-12-31 16:24:46,468 - main - INFO - Epoch 81/5000
2022-12-31 16:24:46,468 - main - INFO - ----------------------------
2022-12-31 16:24:46,469 - main - INFO - training...
2022-12-31 16:33:57,933 - main - DEBUG - Batch 500: running loss = 251860.9771
2022-12-31 16:43:11,253 - main - DEBUG - Batch 1000: running loss = 503533.5624
2022-12-31 16:52:00,477 - main - INFO - Epoch 81 - train: epoch loss = 503.0984
2022-12-31 16:52:00,482 - main - INFO - validating...
2022-12-31 16:58:51,511 - main - DEBUG - Batch 500: running loss = 184155.1150
2022-12-31 16:58:57,242 - main - INFO - Epoch 81 - val: epoch loss = 368.3194
2022-12-31 16:58:57,413 - main - INFO - Saved the best model at epoch 81.
2022-12-31 16:58:57,414 - main - INFO - Epoch 82/5000
2022-12-31 16:58:57,414 - main - INFO - ----------------------------
2022-12-31 16:58:57,415 - main - INFO - training...
2022-12-31 17:08:10,423 - main - DEBUG - Batch 500: running loss = 248666.9172
2022-12-31 17:17:23,656 - main - DEBUG - Batch 1000: running loss = 500543.8254
2022-12-31 17:26:12,388 - main - INFO - Epoch 82 - train: epoch loss = 501.4023
2022-12-31 17:26:12,389 - main - INFO - validating...
2022-12-31 17:33:02,773 - main - DEBUG - Batch 500: running loss = 184473.4224
2022-12-31 17:33:08,494 - main - INFO - Epoch 82 - val: epoch loss = 368.9776
2022-12-31 17:33:08,495 - main - INFO - Epoch 83/5000
2022-12-31 17:33:08,495 - main - INFO - ----------------------------
2022-12-31 17:33:08,496 - main - INFO - training...
2022-12-31 17:42:21,129 - main - DEBUG - Batch 500: running loss = 250732.0399
2022-12-31 17:51:34,775 - main - DEBUG - Batch 1000: running loss = 499994.7444
2022-12-31 18:00:24,208 - main - INFO - Epoch 83 - train: epoch loss = 499.6337
2022-12-31 18:00:24,208 - main - INFO - validating...
2022-12-31 18:07:14,885 - main - DEBUG - Batch 500: running loss = 183248.5121
2022-12-31 18:07:20,606 - main - INFO - Epoch 83 - val: epoch loss = 366.5114
2022-12-31 18:07:20,798 - main - INFO - Saved the best model at epoch 83.
2022-12-31 18:07:20,798 - main - INFO - Epoch 84/5000
2022-12-31 18:07:20,799 - main - INFO - ----------------------------
2022-12-31 18:07:20,799 - main - INFO - training...
2022-12-31 18:16:33,043 - main - DEBUG - Batch 500: running loss = 248500.4915
2022-12-31 18:25:45,838 - main - DEBUG - Batch 1000: running loss = 498033.3158
2022-12-31 18:34:34,282 - main - INFO - Epoch 84 - train: epoch loss = 497.9968
2022-12-31 18:34:34,283 - main - INFO - validating...
2022-12-31 18:41:24,721 - main - DEBUG - Batch 500: running loss = 182507.4894
2022-12-31 18:41:30,454 - main - INFO - Epoch 84 - val: epoch loss = 365.0336
2022-12-31 18:41:30,621 - main - INFO - Saved the best model at epoch 84.
2022-12-31 18:41:30,622 - main - INFO - Epoch 85/5000
2022-12-31 18:41:30,622 - main - INFO - ----------------------------
2022-12-31 18:41:30,623 - main - INFO - training...
2022-12-31 18:50:43,501 - main - DEBUG - Batch 500: running loss = 247701.9328
2022-12-31 18:59:57,206 - main - DEBUG - Batch 1000: running loss = 496955.7711
2022-12-31 19:08:46,101 - main - INFO - Epoch 85 - train: epoch loss = 496.3852
2022-12-31 19:08:46,102 - main - INFO - validating...
2022-12-31 19:15:36,603 - main - DEBUG - Batch 500: running loss = 180984.2986
2022-12-31 19:15:42,314 - main - INFO - Epoch 85 - val: epoch loss = 361.9825
2022-12-31 19:15:42,479 - main - INFO - Saved the best model at epoch 85.
2022-12-31 19:15:42,480 - main - INFO - Epoch 86/5000
2022-12-31 19:15:42,480 - main - INFO - ----------------------------
2022-12-31 19:15:42,481 - main - INFO - training...
2022-12-31 19:24:54,476 - main - DEBUG - Batch 500: running loss = 245985.9446
2022-12-31 19:34:07,449 - main - DEBUG - Batch 1000: running loss = 493950.4905
2022-12-31 19:42:56,454 - main - INFO - Epoch 86 - train: epoch loss = 494.7834
2022-12-31 19:42:56,455 - main - INFO - validating...
2022-12-31 19:49:47,174 - main - DEBUG - Batch 500: running loss = 180351.5923
2022-12-31 19:49:52,893 - main - INFO - Epoch 86 - val: epoch loss = 360.7251
2022-12-31 19:49:53,055 - main - INFO - Saved the best model at epoch 86.
2022-12-31 19:49:53,056 - main - INFO - Epoch 87/5000
2022-12-31 19:49:53,056 - main - INFO - ----------------------------
2022-12-31 19:49:53,058 - main - INFO - training...
2022-12-31 19:59:06,084 - main - DEBUG - Batch 500: running loss = 248476.9688
2022-12-31 20:08:19,302 - main - DEBUG - Batch 1000: running loss = 494447.9809
2022-12-31 20:17:07,848 - main - INFO - Epoch 87 - train: epoch loss = 493.3526
2022-12-31 20:17:07,849 - main - INFO - validating...
2022-12-31 20:23:57,932 - main - DEBUG - Batch 500: running loss = 179064.7076
2022-12-31 20:24:03,656 - main - INFO - Epoch 87 - val: epoch loss = 358.1491
2022-12-31 20:24:03,821 - main - INFO - Saved the best model at epoch 87.
2022-12-31 20:24:03,822 - main - INFO - Epoch 88/5000
2022-12-31 20:24:03,822 - main - INFO - ----------------------------
2022-12-31 20:24:03,823 - main - INFO - training...
2022-12-31 20:33:15,794 - main - DEBUG - Batch 500: running loss = 247588.6429
2022-12-31 20:42:29,180 - main - DEBUG - Batch 1000: running loss = 491764.2462
2022-12-31 20:51:18,286 - main - INFO - Epoch 88 - train: epoch loss = 491.8331
2022-12-31 20:51:18,287 - main - INFO - validating...
2022-12-31 20:58:08,701 - main - DEBUG - Batch 500: running loss = 177928.3397
2022-12-31 20:58:14,423 - main - INFO - Epoch 88 - val: epoch loss = 355.8729
2022-12-31 20:58:14,589 - main - INFO - Saved the best model at epoch 88.
2022-12-31 20:58:14,590 - main - INFO - Epoch 89/5000
2022-12-31 20:58:14,590 - main - INFO - ----------------------------
2022-12-31 20:58:14,591 - main - INFO - training...
2022-12-31 21:07:27,229 - main - DEBUG - Batch 500: running loss = 246067.1528
2022-12-31 21:16:40,260 - main - DEBUG - Batch 1000: running loss = 490068.8117
2022-12-31 21:25:28,807 - main - INFO - Epoch 89 - train: epoch loss = 490.3710
2022-12-31 21:25:28,808 - main - INFO - validating...
2022-12-31 21:32:19,191 - main - DEBUG - Batch 500: running loss = 177368.2325
2022-12-31 21:32:24,906 - main - INFO - Epoch 89 - val: epoch loss = 354.7473
2022-12-31 21:32:25,070 - main - INFO - Saved the best model at epoch 89.
2022-12-31 21:32:25,071 - main - INFO - Epoch 90/5000
2022-12-31 21:32:25,071 - main - INFO - ----------------------------
2022-12-31 21:32:25,072 - main - INFO - training...
2022-12-31 21:41:37,788 - main - DEBUG - Batch 500: running loss = 243923.8073
2022-12-31 21:50:51,331 - main - DEBUG - Batch 1000: running loss = 489147.5108
2022-12-31 21:59:40,511 - main - INFO - Epoch 90 - train: epoch loss = 489.0204
2022-12-31 21:59:40,513 - main - INFO - validating...
2022-12-31 22:06:30,841 - main - DEBUG - Batch 500: running loss = 177153.2326
2022-12-31 22:06:36,576 - main - INFO - Epoch 90 - val: epoch loss = 354.3194
2022-12-31 22:06:36,740 - main - INFO - Saved the best model at epoch 90.
2022-12-31 22:06:36,740 - main - INFO - Epoch 91/5000
2022-12-31 22:06:36,741 - main - INFO - ----------------------------
2022-12-31 22:06:36,741 - main - INFO - training...
2022-12-31 22:15:48,917 - main - DEBUG - Batch 500: running loss = 247725.2110
2022-12-31 22:25:01,919 - main - DEBUG - Batch 1000: running loss = 488155.4770
2022-12-31 22:33:50,784 - main - INFO - Epoch 91 - train: epoch loss = 487.5879
2022-12-31 22:33:50,785 - main - INFO - validating...
2022-12-31 22:40:41,157 - main - DEBUG - Batch 500: running loss = 176743.5672
2022-12-31 22:40:46,875 - main - INFO - Epoch 91 - val: epoch loss = 353.4902
2022-12-31 22:40:47,047 - main - INFO - Saved the best model at epoch 91.
2022-12-31 22:40:47,047 - main - INFO - Epoch 92/5000
2022-12-31 22:40:47,048 - main - INFO - ----------------------------
2022-12-31 22:40:47,049 - main - INFO - training...
2022-12-31 22:49:59,905 - main - DEBUG - Batch 500: running loss = 242398.0966
2022-12-31 22:59:13,382 - main - DEBUG - Batch 1000: running loss = 485370.8362
2022-12-31 23:08:01,915 - main - INFO - Epoch 92 - train: epoch loss = 486.2192
2022-12-31 23:08:01,916 - main - INFO - validating...
2022-12-31 23:14:52,084 - main - DEBUG - Batch 500: running loss = 175378.4901
2022-12-31 23:14:57,801 - main - INFO - Epoch 92 - val: epoch loss = 350.7747
2022-12-31 23:14:57,966 - main - INFO - Saved the best model at epoch 92.
2022-12-31 23:14:57,967 - main - INFO - Epoch 93/5000
2022-12-31 23:14:57,967 - main - INFO - ----------------------------
2022-12-31 23:14:57,969 - main - INFO - training...
2022-12-31 23:24:10,019 - main - DEBUG - Batch 500: running loss = 242114.5408
2022-12-31 23:33:23,291 - main - DEBUG - Batch 1000: running loss = 484944.5970
2022-12-31 23:42:12,438 - main - INFO - Epoch 93 - train: epoch loss = 484.9518
2022-12-31 23:42:12,439 - main - INFO - validating...
2022-12-31 23:49:03,203 - main - DEBUG - Batch 500: running loss = 174666.1757
2022-12-31 23:49:08,910 - main - INFO - Epoch 93 - val: epoch loss = 349.3353
2022-12-31 23:49:09,078 - main - INFO - Saved the best model at epoch 93.
2022-12-31 23:49:09,079 - main - INFO - Epoch 94/5000
2022-12-31 23:49:09,079 - main - INFO - ----------------------------
2022-12-31 23:49:09,080 - main - INFO - training...
2022-12-31 23:58:21,947 - main - DEBUG - Batch 500: running loss = 242093.1942
2023-01-01 00:07:34,941 - main - DEBUG - Batch 1000: running loss = 483943.0495
2023-01-01 00:16:23,360 - main - INFO - Epoch 94 - train: epoch loss = 483.5894
2023-01-01 00:16:23,361 - main - INFO - validating...
2023-01-01 00:23:13,532 - main - DEBUG - Batch 500: running loss = 173425.0438
2023-01-01 00:23:19,249 - main - INFO - Epoch 94 - val: epoch loss = 346.8717
2023-01-01 00:23:19,417 - main - INFO - Saved the best model at epoch 94.
2023-01-01 00:23:19,417 - main - INFO - Epoch 95/5000
2023-01-01 00:23:19,418 - main - INFO - ----------------------------
2023-01-01 00:23:19,419 - main - INFO - training...
2023-01-01 00:32:31,957 - main - DEBUG - Batch 500: running loss = 240148.9614
2023-01-01 00:41:45,486 - main - DEBUG - Batch 1000: running loss = 482743.5697
2023-01-01 00:50:34,686 - main - INFO - Epoch 95 - train: epoch loss = 482.3637
2023-01-01 00:50:34,688 - main - INFO - validating...
2023-01-01 00:57:25,078 - main - DEBUG - Batch 500: running loss = 173474.5439
2023-01-01 00:57:30,777 - main - INFO - Epoch 95 - val: epoch loss = 346.9524
2023-01-01 00:57:30,777 - main - INFO - Epoch 96/5000
2023-01-01 00:57:30,778 - main - INFO - ----------------------------
2023-01-01 00:57:30,778 - main - INFO - training...
2023-01-01 01:06:43,239 - main - DEBUG - Batch 500: running loss = 239547.3843
2023-01-01 01:15:56,226 - main - DEBUG - Batch 1000: running loss = 481974.9453
2023-01-01 01:24:44,787 - main - INFO - Epoch 96 - train: epoch loss = 481.1887
2023-01-01 01:24:44,788 - main - INFO - validating...
2023-01-01 01:31:35,198 - main - DEBUG - Batch 500: running loss = 173497.1167
2023-01-01 01:31:40,929 - main - INFO - Epoch 96 - val: epoch loss = 346.9946
2023-01-01 01:31:40,930 - main - INFO - Epoch 97/5000
2023-01-01 01:31:40,930 - main - INFO - ----------------------------
2023-01-01 01:31:40,931 - main - INFO - training...
2023-01-01 01:40:53,842 - main - DEBUG - Batch 500: running loss = 238510.0206
2023-01-01 01:50:07,502 - main - DEBUG - Batch 1000: running loss = 480250.2597
2023-01-01 01:58:56,421 - main - INFO - Epoch 97 - train: epoch loss = 480.0214
2023-01-01 01:58:56,422 - main - INFO - validating...
2023-01-01 02:05:46,725 - main - DEBUG - Batch 500: running loss = 172011.0708
2023-01-01 02:05:52,452 - main - INFO - Epoch 97 - val: epoch loss = 344.0327
2023-01-01 02:05:52,621 - main - INFO - Saved the best model at epoch 97.
2023-01-01 02:05:52,622 - main - INFO - Epoch 98/5000
2023-01-01 02:05:52,622 - main - INFO - ----------------------------
2023-01-01 02:05:52,623 - main - INFO - training...
2023-01-01 02:15:04,715 - main - DEBUG - Batch 500: running loss = 239295.7241
2023-01-01 02:24:17,671 - main - DEBUG - Batch 1000: running loss = 478187.4149
2023-01-01 02:33:06,552 - main - INFO - Epoch 98 - train: epoch loss = 478.7706
2023-01-01 02:33:06,553 - main - INFO - validating...
2023-01-01 02:39:57,447 - main - DEBUG - Batch 500: running loss = 170444.3715
2023-01-01 02:40:03,176 - main - INFO - Epoch 98 - val: epoch loss = 340.8876
2023-01-01 02:40:03,338 - main - INFO - Saved the best model at epoch 98.
2023-01-01 02:40:03,339 - main - INFO - Epoch 99/5000
2023-01-01 02:40:03,339 - main - INFO - ----------------------------
2023-01-01 02:40:03,340 - main - INFO - training...
2023-01-01 02:49:16,218 - main - DEBUG - Batch 500: running loss = 238244.7045
2023-01-01 02:58:29,534 - main - DEBUG - Batch 1000: running loss = 477408.6129
2023-01-01 03:07:18,079 - main - INFO - Epoch 99 - train: epoch loss = 477.6421
2023-01-01 03:07:18,079 - main - INFO - validating...
2023-01-01 03:14:08,367 - main - DEBUG - Batch 500: running loss = 170171.6982
2023-01-01 03:14:14,076 - main - INFO - Epoch 99 - val: epoch loss = 340.3480
2023-01-01 03:14:14,239 - main - INFO - Saved the best model at epoch 99.
2023-01-01 03:14:14,240 - main - INFO - Epoch 100/5000
2023-01-01 03:14:14,240 - main - INFO - ----------------------------
2023-01-01 03:14:14,241 - main - INFO - training...
2023-01-01 03:23:26,207 - main - DEBUG - Batch 500: running loss = 236017.4316
2023-01-01 03:32:39,517 - main - DEBUG - Batch 1000: running loss = 476136.9158
2023-01-01 03:41:28,544 - main - INFO - Epoch 100 - train: epoch loss = 476.5567
2023-01-01 03:41:28,544 - main - INFO - validating...
2023-01-01 03:48:19,342 - main - DEBUG - Batch 500: running loss = 169723.0499
2023-01-01 03:48:25,074 - main - INFO - Epoch 100 - val: epoch loss = 339.4502
2023-01-01 03:48:25,217 - main - INFO - Saved the model at epoch 100.
2023-01-01 03:48:25,382 - main - INFO - Saved the best model at epoch 100.
2023-01-01 03:48:25,382 - main - INFO - Epoch 101/5000
2023-01-01 03:48:25,383 - main - INFO - ----------------------------
2023-01-01 03:48:25,383 - main - INFO - training...
2023-01-01 03:57:38,045 - main - DEBUG - Batch 500: running loss = 239417.4134
2023-01-01 04:06:51,035 - main - DEBUG - Batch 1000: running loss = 476688.9086
2023-01-01 04:15:39,525 - main - INFO - Epoch 101 - train: epoch loss = 475.4069
2023-01-01 04:15:39,527 - main - INFO - validating...
2023-01-01 04:22:29,676 - main - DEBUG - Batch 500: running loss = 169063.9249
2023-01-01 04:22:35,384 - main - INFO - Epoch 101 - val: epoch loss = 338.1391
2023-01-01 04:22:35,550 - main - INFO - Saved the best model at epoch 101.
2023-01-01 04:22:35,551 - main - INFO - Epoch 102/5000
2023-01-01 04:22:35,551 - main - INFO - ----------------------------
2023-01-01 04:22:35,552 - main - INFO - training...
2023-01-01 04:31:48,122 - main - DEBUG - Batch 500: running loss = 235973.8905
2023-01-01 04:41:01,500 - main - DEBUG - Batch 1000: running loss = 474286.0835
2023-01-01 04:49:50,499 - main - INFO - Epoch 102 - train: epoch loss = 474.2995
2023-01-01 04:49:50,501 - main - INFO - validating...
2023-01-01 04:56:40,917 - main - DEBUG - Batch 500: running loss = 168737.1754
2023-01-01 04:56:46,655 - main - INFO - Epoch 102 - val: epoch loss = 337.4756
2023-01-01 04:56:46,828 - main - INFO - Saved the best model at epoch 102.
2023-01-01 04:56:46,828 - main - INFO - Epoch 103/5000
2023-01-01 04:56:46,828 - main - INFO - ----------------------------
2023-01-01 04:56:46,829 - main - INFO - training...
2023-01-01 05:05:58,999 - main - DEBUG - Batch 500: running loss = 236830.4064
2023-01-01 05:15:11,854 - main - DEBUG - Batch 1000: running loss = 474426.7131
2023-01-01 05:24:00,549 - main - INFO - Epoch 103 - train: epoch loss = 473.2391
2023-01-01 05:24:00,550 - main - INFO - validating...
2023-01-01 05:30:51,183 - main - DEBUG - Batch 500: running loss = 168718.7478
2023-01-01 05:30:56,910 - main - INFO - Epoch 103 - val: epoch loss = 337.4495
2023-01-01 05:30:57,077 - main - INFO - Saved the best model at epoch 103.
2023-01-01 05:30:57,078 - main - INFO - Epoch 104/5000
2023-01-01 05:30:57,078 - main - INFO - ----------------------------
2023-01-01 05:30:57,079 - main - INFO - training...
2023-01-01 05:40:09,821 - main - DEBUG - Batch 500: running loss = 236733.7840
2023-01-01 05:49:23,229 - main - DEBUG - Batch 1000: running loss = 473056.7322
2023-01-01 05:58:11,711 - main - INFO - Epoch 104 - train: epoch loss = 472.3196
2023-01-01 05:58:11,712 - main - INFO - validating...
2023-01-01 06:05:02,318 - main - DEBUG - Batch 500: running loss = 166903.6631
2023-01-01 06:05:08,044 - main - INFO - Epoch 104 - val: epoch loss = 333.8096
2023-01-01 06:05:08,217 - main - INFO - Saved the best model at epoch 104.
2023-01-01 06:05:08,218 - main - INFO - Epoch 105/5000
2023-01-01 06:05:08,218 - main - INFO - ----------------------------
2023-01-01 06:05:08,219 - main - INFO - training...
2023-01-01 06:14:19,376 - main - DEBUG - Batch 500: running loss = 236732.3291
2023-01-01 06:23:32,273 - main - DEBUG - Batch 1000: running loss = 472134.2410
2023-01-01 06:32:21,232 - main - INFO - Epoch 105 - train: epoch loss = 471.2636
2023-01-01 06:32:21,232 - main - INFO - validating...
2023-01-01 06:39:11,981 - main - DEBUG - Batch 500: running loss = 167269.8473
2023-01-01 06:39:17,735 - main - INFO - Epoch 105 - val: epoch loss = 334.5298
2023-01-01 06:39:17,735 - main - INFO - Epoch 106/5000
2023-01-01 06:39:17,736 - main - INFO - ----------------------------
2023-01-01 06:39:17,736 - main - INFO - training...
2023-01-01 06:48:30,482 - main - DEBUG - Batch 500: running loss = 234290.7814
2023-01-01 06:57:43,472 - main - DEBUG - Batch 1000: running loss = 472405.5074
2023-01-01 07:06:31,878 - main - INFO - Epoch 106 - train: epoch loss = 470.2057
2023-01-01 07:06:31,879 - main - INFO - validating...
2023-01-01 07:13:22,340 - main - DEBUG - Batch 500: running loss = 166380.1277
2023-01-01 07:13:28,059 - main - INFO - Epoch 106 - val: epoch loss = 332.7452
2023-01-01 07:13:28,229 - main - INFO - Saved the best model at epoch 106.
2023-01-01 07:13:28,230 - main - INFO - Epoch 107/5000
2023-01-01 07:13:28,230 - main - INFO - ----------------------------
2023-01-01 07:13:28,231 - main - INFO - training...
2023-01-01 07:22:40,414 - main - DEBUG - Batch 500: running loss = 234067.6904
2023-01-01 07:31:53,697 - main - DEBUG - Batch 1000: running loss = 468788.3447
2023-01-01 07:40:42,617 - main - INFO - Epoch 107 - train: epoch loss = 469.2383
2023-01-01 07:40:42,618 - main - INFO - validating...
2023-01-01 07:47:33,496 - main - DEBUG - Batch 500: running loss = 165139.4054
2023-01-01 07:47:39,223 - main - INFO - Epoch 107 - val: epoch loss = 330.2709
2023-01-01 07:47:39,391 - main - INFO - Saved the best model at epoch 107.
2023-01-01 07:47:39,391 - main - INFO - Epoch 108/5000
2023-01-01 07:47:39,392 - main - INFO - ----------------------------
2023-01-01 07:47:39,392 - main - INFO - training...
2023-01-01 07:56:51,659 - main - DEBUG - Batch 500: running loss = 235954.4425
2023-01-01 08:06:04,598 - main - DEBUG - Batch 1000: running loss = 469447.6232
2023-01-01 08:14:53,010 - main - INFO - Epoch 108 - train: epoch loss = 468.3747
2023-01-01 08:14:53,011 - main - INFO - validating...
2023-01-01 08:21:43,647 - main - DEBUG - Batch 500: running loss = 164792.1433
2023-01-01 08:21:49,360 - main - INFO - Epoch 108 - val: epoch loss = 329.5714
2023-01-01 08:21:49,527 - main - INFO - Saved the best model at epoch 108.
2023-01-01 08:21:49,528 - main - INFO - Epoch 109/5000
2023-01-01 08:21:49,528 - main - INFO - ----------------------------
2023-01-01 08:21:49,529 - main - INFO - training...
2023-01-01 08:31:02,169 - main - DEBUG - Batch 500: running loss = 233078.4839
2023-01-01 08:40:15,567 - main - DEBUG - Batch 1000: running loss = 466438.5775
2023-01-01 08:49:04,258 - main - INFO - Epoch 109 - train: epoch loss = 467.4814
2023-01-01 08:49:04,259 - main - INFO - validating...
2023-01-01 08:55:54,600 - main - DEBUG - Batch 500: running loss = 163171.9889
2023-01-01 08:56:00,331 - main - INFO - Epoch 109 - val: epoch loss = 326.3394
2023-01-01 08:56:00,496 - main - INFO - Saved the best model at epoch 109.
2023-01-01 08:56:00,496 - main - INFO - Epoch 110/5000
2023-01-01 08:56:00,497 - main - INFO - ----------------------------
2023-01-01 08:56:00,498 - main - INFO - training...
2023-01-01 09:05:11,731 - main - DEBUG - Batch 500: running loss = 234446.5715
2023-01-01 09:14:23,702 - main - DEBUG - Batch 1000: running loss = 469067.3244
2023-01-01 09:23:12,560 - main - INFO - Epoch 110 - train: epoch loss = 466.5272
2023-01-01 09:23:12,560 - main - INFO - validating...
2023-01-01 09:30:03,086 - main - DEBUG - Batch 500: running loss = 162912.8367
2023-01-01 09:30:08,804 - main - INFO - Epoch 110 - val: epoch loss = 325.8231
2023-01-01 09:30:08,971 - main - INFO - Saved the best model at epoch 110.
2023-01-01 09:30:08,971 - main - INFO - Epoch 111/5000
2023-01-01 09:30:08,971 - main - INFO - ----------------------------
2023-01-01 09:30:08,972 - main - INFO - training...
2023-01-01 09:39:21,693 - main - DEBUG - Batch 500: running loss = 233548.3121
2023-01-01 09:48:34,771 - main - DEBUG - Batch 1000: running loss = 464572.6687
2023-01-01 09:57:23,345 - main - INFO - Epoch 111 - train: epoch loss = 465.6605
2023-01-01 09:57:23,345 - main - INFO - validating...
2023-01-01 10:04:14,758 - main - DEBUG - Batch 500: running loss = 163024.5793
2023-01-01 10:04:20,486 - main - INFO - Epoch 111 - val: epoch loss = 326.0436
2023-01-01 10:04:20,486 - main - INFO - Epoch 112/5000
2023-01-01 10:04:20,487 - main - INFO - ----------------------------
2023-01-01 10:04:20,487 - main - INFO - training...
2023-01-01 10:13:31,902 - main - DEBUG - Batch 500: running loss = 232770.5795
2023-01-01 10:22:45,203 - main - DEBUG - Batch 1000: running loss = 465655.6471
2023-01-01 10:31:34,228 - main - INFO - Epoch 112 - train: epoch loss = 464.7710
2023-01-01 10:31:34,229 - main - INFO - validating...
2023-01-01 10:38:25,281 - main - DEBUG - Batch 500: running loss = 163118.6370
2023-01-01 10:38:31,006 - main - INFO - Epoch 112 - val: epoch loss = 326.2327
2023-01-01 10:38:31,007 - main - INFO - Epoch 113/5000
2023-01-01 10:38:31,007 - main - INFO - ----------------------------
2023-01-01 10:38:31,008 - main - INFO - training...
2023-01-01 10:47:43,543 - main - DEBUG - Batch 500: running loss = 233347.3685
2023-01-01 10:56:56,533 - main - DEBUG - Batch 1000: running loss = 466404.5240
2023-01-01 11:05:44,972 - main - INFO - Epoch 113 - train: epoch loss = 463.9026
2023-01-01 11:05:44,973 - main - INFO - validating...
2023-01-01 11:12:35,792 - main - DEBUG - Batch 500: running loss = 161673.1922
2023-01-01 11:12:41,518 - main - INFO - Epoch 113 - val: epoch loss = 323.3327
2023-01-01 11:12:41,692 - main - INFO - Saved the best model at epoch 113.
2023-01-01 11:12:41,692 - main - INFO - Epoch 114/5000
2023-01-01 11:12:41,693 - main - INFO - ----------------------------
2023-01-01 11:12:41,694 - main - INFO - training...
2023-01-01 11:21:54,354 - main - DEBUG - Batch 500: running loss = 231838.1186
2023-01-01 11:31:07,958 - main - DEBUG - Batch 1000: running loss = 461830.7339
2023-01-01 11:39:57,117 - main - INFO - Epoch 114 - train: epoch loss = 463.1682
2023-01-01 11:39:57,118 - main - INFO - validating...
2023-01-01 11:46:47,597 - main - DEBUG - Batch 500: running loss = 163050.2043
2023-01-01 11:46:53,326 - main - INFO - Epoch 114 - val: epoch loss = 326.0764
2023-01-01 11:46:53,327 - main - INFO - Epoch 115/5000
2023-01-01 11:46:53,327 - main - INFO - ----------------------------
2023-01-01 11:46:53,328 - main - INFO - training...
2023-01-01 11:56:05,486 - main - DEBUG - Batch 500: running loss = 230697.5017
2023-01-01 12:05:18,419 - main - DEBUG - Batch 1000: running loss = 462086.4071
2023-01-01 12:14:07,014 - main - INFO - Epoch 115 - train: epoch loss = 462.2990
2023-01-01 12:14:07,015 - main - INFO - validating...
2023-01-01 12:20:57,785 - main - DEBUG - Batch 500: running loss = 161341.2549
2023-01-01 12:21:03,522 - main - INFO - Epoch 115 - val: epoch loss = 322.6808
2023-01-01 12:21:03,691 - main - INFO - Saved the best model at epoch 115.
2023-01-01 12:21:03,692 - main - INFO - Epoch 116/5000
2023-01-01 12:21:03,692 - main - INFO - ----------------------------
2023-01-01 12:21:03,693 - main - INFO - training...
2023-01-01 12:30:16,541 - main - DEBUG - Batch 500: running loss = 232611.9949
2023-01-01 12:39:30,064 - main - DEBUG - Batch 1000: running loss = 462139.4234
2023-01-01 12:48:18,618 - main - INFO - Epoch 116 - train: epoch loss = 461.4082
2023-01-01 12:48:18,619 - main - INFO - validating...
2023-01-01 12:55:08,886 - main - DEBUG - Batch 500: running loss = 160437.8979
2023-01-01 12:55:14,595 - main - INFO - Epoch 116 - val: epoch loss = 320.8732
2023-01-01 12:55:14,765 - main - INFO - Saved the best model at epoch 116.
2023-01-01 12:55:14,766 - main - INFO - Epoch 117/5000
2023-01-01 12:55:14,766 - main - INFO - ----------------------------
2023-01-01 12:55:14,767 - main - INFO - training...
2023-01-01 13:04:26,904 - main - DEBUG - Batch 500: running loss = 229964.3305
2023-01-01 13:13:40,147 - main - DEBUG - Batch 1000: running loss = 461758.5153
2023-01-01 13:22:29,314 - main - INFO - Epoch 117 - train: epoch loss = 460.7038
2023-01-01 13:22:29,314 - main - INFO - validating...
2023-01-01 13:29:20,132 - main - DEBUG - Batch 500: running loss = 161310.6174
2023-01-01 13:29:25,858 - main - INFO - Epoch 117 - val: epoch loss = 322.6050
2023-01-01 13:29:25,860 - main - INFO - Epoch 118/5000
2023-01-01 13:29:25,860 - main - INFO - ----------------------------
2023-01-01 13:29:25,861 - main - INFO - training...
2023-01-01 13:38:38,842 - main - DEBUG - Batch 500: running loss = 230671.0836
2023-01-01 13:47:51,869 - main - DEBUG - Batch 1000: running loss = 459734.4244
2023-01-01 13:56:40,407 - main - INFO - Epoch 118 - train: epoch loss = 459.9856
2023-01-01 13:56:40,408 - main - INFO - validating...
2023-01-01 14:03:30,839 - main - DEBUG - Batch 500: running loss = 159635.7847
2023-01-01 14:03:36,553 - main - INFO - Epoch 118 - val: epoch loss = 319.2515
2023-01-01 14:03:36,722 - main - INFO - Saved the best model at epoch 118.
2023-01-01 14:03:36,723 - main - INFO - Epoch 119/5000
2023-01-01 14:03:36,724 - main - INFO - ----------------------------
2023-01-01 14:03:36,725 - main - INFO - training...
2023-01-01 14:12:48,925 - main - DEBUG - Batch 500: running loss = 229844.9052
2023-01-01 14:22:02,398 - main - DEBUG - Batch 1000: running loss = 458369.6467
2023-01-01 14:30:51,501 - main - INFO - Epoch 119 - train: epoch loss = 459.0132
2023-01-01 14:30:51,502 - main - INFO - validating...
2023-01-01 14:37:42,684 - main - DEBUG - Batch 500: running loss = 158894.3652
2023-01-01 14:37:48,410 - main - INFO - Epoch 119 - val: epoch loss = 317.7722
2023-01-01 14:37:48,580 - main - INFO - Saved the best model at epoch 119.
2023-01-01 14:37:48,581 - main - INFO - Epoch 120/5000
2023-01-01 14:37:48,582 - main - INFO - ----------------------------
2023-01-01 14:37:48,582 - main - INFO - training...
2023-01-01 14:47:01,043 - main - DEBUG - Batch 500: running loss = 231206.6453
2023-01-01 14:56:14,063 - main - DEBUG - Batch 1000: running loss = 458850.8148
2023-01-01 15:05:02,533 - main - INFO - Epoch 120 - train: epoch loss = 458.3120
2023-01-01 15:05:02,534 - main - INFO - validating...
2023-01-01 15:11:53,191 - main - DEBUG - Batch 500: running loss = 158597.5914
2023-01-01 15:11:58,932 - main - INFO - Epoch 120 - val: epoch loss = 317.1883
2023-01-01 15:11:59,103 - main - INFO - Saved the best model at epoch 120.
2023-01-01 15:11:59,104 - main - INFO - Epoch 121/5000
2023-01-01 15:11:59,104 - main - INFO - ----------------------------
2023-01-01 15:11:59,105 - main - INFO - training...
2023-01-01 15:21:11,965 - main - DEBUG - Batch 500: running loss = 229099.6041
2023-01-01 15:30:25,503 - main - DEBUG - Batch 1000: running loss = 458387.7701
2023-01-01 15:39:14,353 - main - INFO - Epoch 121 - train: epoch loss = 457.6200
2023-01-01 15:39:14,354 - main - INFO - validating...
2023-01-01 15:46:05,040 - main - DEBUG - Batch 500: running loss = 157893.1309
2023-01-01 15:46:10,770 - main - INFO - Epoch 121 - val: epoch loss = 315.7778
2023-01-01 15:46:10,939 - main - INFO - Saved the best model at epoch 121.
2023-01-01 15:46:10,940 - main - INFO - Epoch 122/5000
2023-01-01 15:46:10,940 - main - INFO - ----------------------------
2023-01-01 15:46:10,941 - main - INFO - training...
2023-01-01 15:55:23,132 - main - DEBUG - Batch 500: running loss = 230991.0706
2023-01-01 16:04:36,056 - main - DEBUG - Batch 1000: running loss = 457514.8176
2023-01-01 16:13:25,029 - main - INFO - Epoch 122 - train: epoch loss = 456.9320
2023-01-01 16:13:25,030 - main - INFO - validating...
2023-01-01 16:20:15,639 - main - DEBUG - Batch 500: running loss = 158517.8748
2023-01-01 16:20:21,366 - main - INFO - Epoch 122 - val: epoch loss = 317.0236
2023-01-01 16:20:21,366 - main - INFO - Epoch 123/5000
2023-01-01 16:20:21,367 - main - INFO - ----------------------------
2023-01-01 16:20:21,367 - main - INFO - training...
2023-01-01 16:29:34,333 - main - DEBUG - Batch 500: running loss = 225829.9132
2023-01-01 16:38:47,713 - main - DEBUG - Batch 1000: running loss = 456125.0776
2023-01-01 16:47:36,311 - main - INFO - Epoch 123 - train: epoch loss = 456.1686
2023-01-01 16:47:36,312 - main - INFO - validating...
2023-01-01 16:54:26,535 - main - DEBUG - Batch 500: running loss = 157305.7892
2023-01-01 16:54:32,242 - main - INFO - Epoch 123 - val: epoch loss = 314.5984
2023-01-01 16:54:32,414 - main - INFO - Saved the best model at epoch 123.
2023-01-01 16:54:32,415 - main - INFO - Epoch 124/5000
2023-01-01 16:54:32,415 - main - INFO - ----------------------------
2023-01-01 16:54:32,416 - main - INFO - training...
2023-01-01 17:03:44,508 - main - DEBUG - Batch 500: running loss = 228922.3250
2023-01-01 17:12:57,500 - main - DEBUG - Batch 1000: running loss = 455955.7306
2023-01-01 17:21:45,857 - main - INFO - Epoch 124 - train: epoch loss = 455.5018
2023-01-01 17:21:45,858 - main - INFO - validating...
2023-01-01 17:28:36,279 - main - DEBUG - Batch 500: running loss = 157148.5081
2023-01-01 17:28:41,991 - main - INFO - Epoch 124 - val: epoch loss = 314.2745
2023-01-01 17:28:42,160 - main - INFO - Saved the best model at epoch 124.
2023-01-01 17:28:42,161 - main - INFO - Epoch 125/5000
2023-01-01 17:28:42,161 - main - INFO - ----------------------------
2023-01-01 17:28:42,162 - main - INFO - training...
2023-01-01 17:37:54,310 - main - DEBUG - Batch 500: running loss = 226286.4485
2023-01-01 17:47:07,745 - main - DEBUG - Batch 1000: running loss = 452625.3604
2023-01-01 17:55:56,880 - main - INFO - Epoch 125 - train: epoch loss = 454.8841
2023-01-01 17:55:56,887 - main - INFO - validating...
2023-01-01 18:02:47,432 - main - DEBUG - Batch 500: running loss = 157846.1971
2023-01-01 18:02:53,153 - main - INFO - Epoch 125 - val: epoch loss = 315.6801
2023-01-01 18:02:53,154 - main - INFO - Epoch 126/5000
2023-01-01 18:02:53,154 - main - INFO - ----------------------------
2023-01-01 18:02:53,155 - main - INFO - training...
2023-01-01 18:12:05,614 - main - DEBUG - Batch 500: running loss = 227325.9223
2023-01-01 18:21:18,569 - main - DEBUG - Batch 1000: running loss = 454652.9652
2023-01-01 18:30:06,960 - main - INFO - Epoch 126 - train: epoch loss = 454.0986
2023-01-01 18:30:06,961 - main - INFO - validating...
2023-01-01 18:36:58,153 - main - DEBUG - Batch 500: running loss = 156172.8300
2023-01-01 18:37:03,903 - main - INFO - Epoch 126 - val: epoch loss = 312.3354
2023-01-01 18:37:04,078 - main - INFO - Saved the best model at epoch 126.
2023-01-01 18:37:04,078 - main - INFO - Epoch 127/5000
2023-01-01 18:37:04,078 - main - INFO - ----------------------------
2023-01-01 18:37:04,079 - main - INFO - training...
2023-01-01 18:46:16,746 - main - DEBUG - Batch 500: running loss = 224507.8120
2023-01-01 18:55:30,288 - main - DEBUG - Batch 1000: running loss = 452210.3494
2023-01-01 19:04:19,220 - main - INFO - Epoch 127 - train: epoch loss = 453.5318
2023-01-01 19:04:19,221 - main - INFO - validating...
2023-01-01 19:11:10,427 - main - DEBUG - Batch 500: running loss = 156497.8100
2023-01-01 19:11:16,155 - main - INFO - Epoch 127 - val: epoch loss = 312.9809
2023-01-01 19:11:16,155 - main - INFO - Epoch 128/5000
2023-01-01 19:11:16,156 - main - INFO - ----------------------------
2023-01-01 19:11:16,157 - main - INFO - training...
2023-01-01 19:20:28,338 - main - DEBUG - Batch 500: running loss = 227216.9637
2023-01-01 19:29:41,179 - main - DEBUG - Batch 1000: running loss = 453646.3462
2023-01-01 19:38:29,910 - main - INFO - Epoch 128 - train: epoch loss = 452.8579
2023-01-01 19:38:29,911 - main - INFO - validating...
2023-01-01 19:45:20,969 - main - DEBUG - Batch 500: running loss = 156615.9483
2023-01-01 19:45:26,709 - main - INFO - Epoch 128 - val: epoch loss = 313.2212
2023-01-01 19:45:26,710 - main - INFO - Epoch 129/5000
2023-01-01 19:45:26,710 - main - INFO - ----------------------------
2023-01-01 19:45:26,711 - main - INFO - training...
2023-01-01 19:54:39,523 - main - DEBUG - Batch 500: running loss = 226025.7267
2023-01-01 20:03:52,891 - main - DEBUG - Batch 1000: running loss = 451292.5026
2023-01-01 20:12:41,448 - main - INFO - Epoch 129 - train: epoch loss = 452.2249
2023-01-01 20:12:41,449 - main - INFO - validating...
2023-01-01 20:19:32,532 - main - DEBUG - Batch 500: running loss = 156218.6553
2023-01-01 20:19:38,258 - main - INFO - Epoch 129 - val: epoch loss = 312.4205
2023-01-01 20:19:38,259 - main - INFO - Epoch 130/5000
2023-01-01 20:19:38,259 - main - INFO - ----------------------------
2023-01-01 20:19:38,260 - main - INFO - training...
2023-01-01 20:28:50,163 - main - DEBUG - Batch 500: running loss = 226472.6039
2023-01-01 20:38:03,369 - main - DEBUG - Batch 1000: running loss = 451738.6138
2023-01-01 20:46:52,361 - main - INFO - Epoch 130 - train: epoch loss = 451.5118
2023-01-01 20:46:52,362 - main - INFO - validating...
2023-01-01 20:53:43,664 - main - DEBUG - Batch 500: running loss = 154850.2616
2023-01-01 20:53:49,397 - main - INFO - Epoch 130 - val: epoch loss = 309.6907
2023-01-01 20:53:49,570 - main - INFO - Saved the best model at epoch 130.
2023-01-01 20:53:49,570 - main - INFO - Epoch 131/5000
2023-01-01 20:53:49,570 - main - INFO - ----------------------------
2023-01-01 20:53:49,571 - main - INFO - training...
2023-01-01 21:03:02,287 - main - DEBUG - Batch 500: running loss = 226781.6054
2023-01-01 21:12:15,298 - main - DEBUG - Batch 1000: running loss = 451811.2643
2023-01-01 21:21:03,794 - main - INFO - Epoch 131 - train: epoch loss = 450.9355
2023-01-01 21:21:03,795 - main - INFO - validating...
2023-01-01 21:27:54,859 - main - DEBUG - Batch 500: running loss = 155071.8044
2023-01-01 21:28:00,584 - main - INFO - Epoch 131 - val: epoch loss = 310.1122
2023-01-01 21:28:00,585 - main - INFO - Epoch 132/5000
2023-01-01 21:28:00,585 - main - INFO - ----------------------------
2023-01-01 21:28:00,586 - main - INFO - training...
2023-01-01 21:37:13,159 - main - DEBUG - Batch 500: running loss = 225641.0626
2023-01-01 21:46:26,746 - main - DEBUG - Batch 1000: running loss = 450285.1361
2023-01-01 21:55:15,956 - main - INFO - Epoch 132 - train: epoch loss = 450.3227
2023-01-01 21:55:15,956 - main - INFO - validating...
2023-01-01 22:02:07,064 - main - DEBUG - Batch 500: running loss = 154188.9002
2023-01-01 22:02:12,790 - main - INFO - Epoch 132 - val: epoch loss = 308.3542
2023-01-01 22:02:12,963 - main - INFO - Saved the best model at epoch 132.
2023-01-01 22:02:12,964 - main - INFO - Epoch 133/5000
2023-01-01 22:02:12,964 - main - INFO - ----------------------------
2023-01-01 22:02:12,965 - main - INFO - training...
2023-01-01 22:11:25,080 - main - DEBUG - Batch 500: running loss = 224989.9336
2023-01-01 22:20:37,915 - main - DEBUG - Batch 1000: running loss = 449554.3772
2023-01-01 22:29:26,504 - main - INFO - Epoch 133 - train: epoch loss = 449.7812
2023-01-01 22:29:26,505 - main - INFO - validating...
2023-01-01 22:36:17,695 - main - DEBUG - Batch 500: running loss = 153877.6813
2023-01-01 22:36:23,466 - main - INFO - Epoch 133 - val: epoch loss = 307.7389
2023-01-01 22:36:23,642 - main - INFO - Saved the best model at epoch 133.
2023-01-01 22:36:23,643 - main - INFO - Epoch 134/5000
2023-01-01 22:36:23,643 - main - INFO - ----------------------------
2023-01-01 22:36:23,644 - main - INFO - training...
2023-01-01 22:45:36,499 - main - DEBUG - Batch 500: running loss = 224241.6139
2023-01-01 22:54:50,036 - main - DEBUG - Batch 1000: running loss = 448320.8359
2023-01-01 23:03:38,665 - main - INFO - Epoch 134 - train: epoch loss = 449.1244
2023-01-01 23:03:38,665 - main - INFO - validating...
2023-01-01 23:10:29,428 - main - DEBUG - Batch 500: running loss = 153612.8548
2023-01-01 23:10:35,157 - main - INFO - Epoch 134 - val: epoch loss = 307.2003
2023-01-01 23:10:35,330 - main - INFO - Saved the best model at epoch 134.
2023-01-01 23:10:35,331 - main - INFO - Epoch 135/5000
2023-01-01 23:10:35,331 - main - INFO - ----------------------------
2023-01-01 23:10:35,332 - main - INFO - training...
2023-01-01 23:19:46,630 - main - DEBUG - Batch 500: running loss = 223663.2093
2023-01-01 23:28:58,892 - main - DEBUG - Batch 1000: running loss = 451192.8086
2023-01-01 23:37:47,732 - main - INFO - Epoch 135 - train: epoch loss = 448.5569
2023-01-01 23:37:47,734 - main - INFO - validating...
2023-01-01 23:44:38,885 - main - DEBUG - Batch 500: running loss = 153226.4269
2023-01-01 23:44:44,631 - main - INFO - Epoch 135 - val: epoch loss = 306.4279
2023-01-01 23:44:44,799 - main - INFO - Saved the best model at epoch 135.
2023-01-01 23:44:44,799 - main - INFO - Epoch 136/5000
2023-01-01 23:44:44,800 - main - INFO - ----------------------------
2023-01-01 23:44:44,800 - main - INFO - training...
2023-01-01 23:53:57,649 - main - DEBUG - Batch 500: running loss = 223485.8455
2023-01-02 00:03:10,733 - main - DEBUG - Batch 1000: running loss = 449029.1806
2023-01-02 00:11:59,256 - main - INFO - Epoch 136 - train: epoch loss = 448.0836
2023-01-02 00:11:59,257 - main - INFO - validating...
2023-01-02 00:18:49,736 - main - DEBUG - Batch 500: running loss = 153439.9882
2023-01-02 00:18:55,472 - main - INFO - Epoch 136 - val: epoch loss = 306.8626
2023-01-02 00:18:55,472 - main - INFO - Epoch 137/5000
2023-01-02 00:18:55,472 - main - INFO - ----------------------------
2023-01-02 00:18:55,473 - main - INFO - training...
2023-01-02 00:28:07,456 - main - DEBUG - Batch 500: running loss = 224827.6115
2023-01-02 00:37:20,881 - main - DEBUG - Batch 1000: running loss = 449377.6289
2023-01-02 00:46:09,948 - main - INFO - Epoch 137 - train: epoch loss = 447.4743
2023-01-02 00:46:09,949 - main - INFO - validating...
2023-01-02 00:53:00,881 - main - DEBUG - Batch 500: running loss = 152773.5008
2023-01-02 00:53:06,602 - main - INFO - Epoch 137 - val: epoch loss = 305.5242
2023-01-02 00:53:06,770 - main - INFO - Saved the best model at epoch 137.
2023-01-02 00:53:06,770 - main - INFO - Epoch 138/5000
2023-01-02 00:53:06,771 - main - INFO - ----------------------------
2023-01-02 00:53:06,771 - main - INFO - training...
2023-01-02 01:02:19,089 - main - DEBUG - Batch 500: running loss = 224754.9326
2023-01-02 01:11:31,845 - main - DEBUG - Batch 1000: running loss = 446993.3613
2023-01-02 01:20:20,055 - main - INFO - Epoch 138 - train: epoch loss = 446.8683
2023-01-02 01:20:20,056 - main - INFO - validating...
2023-01-02 01:27:10,514 - main - DEBUG - Batch 500: running loss = 152206.9608
2023-01-02 01:27:16,239 - main - INFO - Epoch 138 - val: epoch loss = 304.3968
2023-01-02 01:27:16,404 - main - INFO - Saved the best model at epoch 138.
2023-01-02 01:27:16,405 - main - INFO - Epoch 139/5000
2023-01-02 01:27:16,405 - main - INFO - ----------------------------
2023-01-02 01:27:16,406 - main - INFO - training...
2023-01-02 01:36:28,997 - main - DEBUG - Batch 500: running loss = 222898.2321
2023-01-02 01:45:42,427 - main - DEBUG - Batch 1000: running loss = 444536.2325
2023-01-02 01:54:31,394 - main - INFO - Epoch 139 - train: epoch loss = 446.3598
2023-01-02 01:54:31,395 - main - INFO - validating...
2023-01-02 02:01:22,268 - main - DEBUG - Batch 500: running loss = 151964.5111
2023-01-02 02:01:27,991 - main - INFO - Epoch 139 - val: epoch loss = 303.9127
2023-01-02 02:01:28,161 - main - INFO - Saved the best model at epoch 139.
2023-01-02 02:01:28,162 - main - INFO - Epoch 140/5000
2023-01-02 02:01:28,162 - main - INFO - ----------------------------
2023-01-02 02:01:28,163 - main - INFO - training...
2023-01-02 02:10:40,001 - main - DEBUG - Batch 500: running loss = 220979.8160
2023-01-02 02:19:52,664 - main - DEBUG - Batch 1000: running loss = 445811.3038
2023-01-02 02:28:41,218 - main - INFO - Epoch 140 - train: epoch loss = 445.8030
2023-01-02 02:28:41,218 - main - INFO - validating...
2023-01-02 02:35:32,417 - main - DEBUG - Batch 500: running loss = 151638.7037
2023-01-02 02:35:38,153 - main - INFO - Epoch 140 - val: epoch loss = 303.2420
2023-01-02 02:35:38,319 - main - INFO - Saved the best model at epoch 140.
2023-01-02 02:35:38,320 - main - INFO - Epoch 141/5000
2023-01-02 02:35:38,320 - main - INFO - ----------------------------
2023-01-02 02:35:38,321 - main - INFO - training...
2023-01-02 02:44:50,995 - main - DEBUG - Batch 500: running loss = 221349.4121
2023-01-02 02:54:04,356 - main - DEBUG - Batch 1000: running loss = 443446.3330
2023-01-02 03:02:52,767 - main - INFO - Epoch 141 - train: epoch loss = 445.2198
2023-01-02 03:02:52,768 - main - INFO - validating...
2023-01-02 03:09:43,451 - main - DEBUG - Batch 500: running loss = 150644.7888
2023-01-02 03:09:49,166 - main - INFO - Epoch 141 - val: epoch loss = 301.2747
2023-01-02 03:09:49,341 - main - INFO - Saved the best model at epoch 141.
2023-01-02 03:09:49,342 - main - INFO - Epoch 142/5000
2023-01-02 03:09:49,342 - main - INFO - ----------------------------
2023-01-02 03:09:49,343 - main - INFO - training...
2023-01-02 03:19:00,973 - main - DEBUG - Batch 500: running loss = 222398.4415
2023-01-02 03:28:13,854 - main - DEBUG - Batch 1000: running loss = 444794.0179
2023-01-02 03:37:02,628 - main - INFO - Epoch 142 - train: epoch loss = 444.7625
2023-01-02 03:37:02,629 - main - INFO - validating...
2023-01-02 03:43:53,362 - main - DEBUG - Batch 500: running loss = 150824.3822
2023-01-02 03:43:59,090 - main - INFO - Epoch 142 - val: epoch loss = 301.6200
2023-01-02 03:43:59,091 - main - INFO - Epoch 143/5000
2023-01-02 03:43:59,092 - main - INFO - ----------------------------
2023-01-02 03:43:59,092 - main - INFO - training...
2023-01-02 03:53:11,544 - main - DEBUG - Batch 500: running loss = 220815.6829
2023-01-02 04:02:24,268 - main - DEBUG - Batch 1000: running loss = 444438.9952
2023-01-02 04:11:12,444 - main - INFO - Epoch 143 - train: epoch loss = 444.1903
2023-01-02 04:11:12,445 - main - INFO - validating...
2023-01-02 04:18:02,798 - main - DEBUG - Batch 500: running loss = 151409.0509
2023-01-02 04:18:08,515 - main - INFO - Epoch 143 - val: epoch loss = 302.7990
2023-01-02 04:18:08,516 - main - INFO - Epoch 144/5000
2023-01-02 04:18:08,517 - main - INFO - ----------------------------
2023-01-02 04:18:08,517 - main - INFO - training...
2023-01-02 04:27:20,839 - main - DEBUG - Batch 500: running loss = 221542.8622
2023-01-02 04:36:34,094 - main - DEBUG - Batch 1000: running loss = 444231.0559
2023-01-02 04:45:22,920 - main - INFO - Epoch 144 - train: epoch loss = 443.7327
2023-01-02 04:45:22,921 - main - INFO - validating...
2023-01-02 04:52:14,414 - main - DEBUG - Batch 500: running loss = 150517.2117
2023-01-02 04:52:20,134 - main - INFO - Epoch 144 - val: epoch loss = 301.0075
2023-01-02 04:52:20,306 - main - INFO - Saved the best model at epoch 144.
2023-01-02 04:52:20,307 - main - INFO - Epoch 145/5000
2023-01-02 04:52:20,307 - main - INFO - ----------------------------
2023-01-02 04:52:20,308 - main - INFO - training...
2023-01-02 05:01:32,496 - main - DEBUG - Batch 500: running loss = 221614.8304
2023-01-02 05:10:45,248 - main - DEBUG - Batch 1000: running loss = 444550.2095
2023-01-02 05:19:33,487 - main - INFO - Epoch 145 - train: epoch loss = 443.2461
2023-01-02 05:19:33,488 - main - INFO - validating...
2023-01-02 05:26:24,702 - main - DEBUG - Batch 500: running loss = 150456.8982
2023-01-02 05:26:30,418 - main - INFO - Epoch 145 - val: epoch loss = 300.8830
2023-01-02 05:26:30,582 - main - INFO - Saved the best model at epoch 145.
2023-01-02 05:26:30,582 - main - INFO - Epoch 146/5000
2023-01-02 05:26:30,583 - main - INFO - ----------------------------
2023-01-02 05:26:30,584 - main - INFO - training...
2023-01-02 05:35:43,018 - main - DEBUG - Batch 500: running loss = 220862.9494
2023-01-02 05:44:56,338 - main - DEBUG - Batch 1000: running loss = 443860.6103
2023-01-02 05:53:44,868 - main - INFO - Epoch 146 - train: epoch loss = 442.6925
2023-01-02 05:53:44,874 - main - INFO - validating...
2023-01-02 06:00:35,602 - main - DEBUG - Batch 500: running loss = 149610.4952
2023-01-02 06:00:41,332 - main - INFO - Epoch 146 - val: epoch loss = 299.1905
2023-01-02 06:00:41,500 - main - INFO - Saved the best model at epoch 146.
2023-01-02 06:00:41,501 - main - INFO - Epoch 147/5000
2023-01-02 06:00:41,501 - main - INFO - ----------------------------
2023-01-02 06:00:41,502 - main - INFO - training...
2023-01-02 06:09:53,929 - main - DEBUG - Batch 500: running loss = 221846.9352
2023-01-02 06:19:07,243 - main - DEBUG - Batch 1000: running loss = 440965.7750
2023-01-02 06:27:56,209 - main - INFO - Epoch 147 - train: epoch loss = 442.1967
2023-01-02 06:27:56,209 - main - INFO - validating...
2023-01-02 06:34:47,710 - main - DEBUG - Batch 500: running loss = 149442.1343
2023-01-02 06:34:53,437 - main - INFO - Epoch 147 - val: epoch loss = 298.8488
2023-01-02 06:34:53,605 - main - INFO - Saved the best model at epoch 147.
2023-01-02 06:34:53,606 - main - INFO - Epoch 148/5000
2023-01-02 06:34:53,606 - main - INFO - ----------------------------
2023-01-02 06:34:53,607 - main - INFO - training...
2023-01-02 06:44:06,321 - main - DEBUG - Batch 500: running loss = 219457.7913
2023-01-02 06:53:19,743 - main - DEBUG - Batch 1000: running loss = 441781.5191
2023-01-02 07:02:08,738 - main - INFO - Epoch 148 - train: epoch loss = 441.6802
2023-01-02 07:02:08,739 - main - INFO - validating...
2023-01-02 07:09:01,542 - main - DEBUG - Batch 500: running loss = 149798.6158
2023-01-02 07:09:07,267 - main - INFO - Epoch 148 - val: epoch loss = 299.5631
2023-01-02 07:09:07,267 - main - INFO - Epoch 149/5000
2023-01-02 07:09:07,268 - main - INFO - ----------------------------
2023-01-02 07:09:07,268 - main - INFO - training...
2023-01-02 07:18:20,117 - main - DEBUG - Batch 500: running loss = 221044.6627
2023-01-02 07:27:33,647 - main - DEBUG - Batch 1000: running loss = 442263.6362
2023-01-02 07:36:22,733 - main - INFO - Epoch 149 - train: epoch loss = 441.3410
2023-01-02 07:36:22,734 - main - INFO - validating...
2023-01-02 07:43:16,868 - main - DEBUG - Batch 500: running loss = 148812.8535
2023-01-02 07:43:22,617 - main - INFO - Epoch 149 - val: epoch loss = 297.5975
2023-01-02 07:43:22,786 - main - INFO - Saved the best model at epoch 149.
2023-01-02 07:43:22,787 - main - INFO - Epoch 150/5000
2023-01-02 07:43:22,787 - main - INFO - ----------------------------
2023-01-02 07:43:22,788 - main - INFO - training...
2023-01-02 07:52:35,863 - main - DEBUG - Batch 500: running loss = 221314.2970
2023-01-02 08:01:49,504 - main - DEBUG - Batch 1000: running loss = 440555.0497
2023-01-02 08:10:38,804 - main - INFO - Epoch 150 - train: epoch loss = 440.8559
2023-01-02 08:10:38,805 - main - INFO - validating...
2023-01-02 08:17:31,617 - main - DEBUG - Batch 500: running loss = 148562.2916
2023-01-02 08:17:37,343 - main - INFO - Epoch 150 - val: epoch loss = 297.0899
2023-01-02 08:17:37,511 - main - INFO - Saved the best model at epoch 150.
2023-01-02 08:17:37,511 - main - INFO - Epoch 151/5000
2023-01-02 08:17:37,512 - main - INFO - ----------------------------
2023-01-02 08:17:37,513 - main - INFO - training...
2023-01-02 08:26:50,595 - main - DEBUG - Batch 500: running loss = 220228.4044
2023-01-02 08:36:04,239 - main - DEBUG - Batch 1000: running loss = 441041.6240
2023-01-02 08:44:53,475 - main - INFO - Epoch 151 - train: epoch loss = 440.3821
2023-01-02 08:44:53,476 - main - INFO - validating...
2023-01-02 08:51:46,106 - main - DEBUG - Batch 500: running loss = 148070.8318
2023-01-02 08:51:51,825 - main - INFO - Epoch 151 - val: epoch loss = 296.1120
2023-01-02 08:51:51,990 - main - INFO - Saved the best model at epoch 151.
2023-01-02 08:51:51,991 - main - INFO - Epoch 152/5000
2023-01-02 08:51:51,991 - main - INFO - ----------------------------
2023-01-02 08:51:51,992 - main - INFO - training...
2023-01-02 09:01:05,194 - main - DEBUG - Batch 500: running loss = 219414.6803
2023-01-02 09:10:18,992 - main - DEBUG - Batch 1000: running loss = 438398.2396
2023-01-02 09:19:08,343 - main - INFO - Epoch 152 - train: epoch loss = 440.0249
2023-01-02 09:19:08,344 - main - INFO - validating...
2023-01-02 09:25:59,563 - main - DEBUG - Batch 500: running loss = 148101.0556
2023-01-02 09:26:05,285 - main - INFO - Epoch 152 - val: epoch loss = 296.1651
2023-01-02 09:26:05,285 - main - INFO - Epoch 153/5000
2023-01-02 09:26:05,285 - main - INFO - ----------------------------
2023-01-02 09:26:05,286 - main - INFO - training...
2023-01-02 09:35:18,486 - main - DEBUG - Batch 500: running loss = 217675.2516
2023-01-02 09:44:32,284 - main - DEBUG - Batch 1000: running loss = 439150.7722
2023-01-02 09:53:21,616 - main - INFO - Epoch 153 - train: epoch loss = 439.5226
2023-01-02 09:53:21,617 - main - INFO - validating...
2023-01-02 10:00:13,237 - main - DEBUG - Batch 500: running loss = 147284.9624
2023-01-02 10:00:18,978 - main - INFO - Epoch 153 - val: epoch loss = 294.5408
2023-01-02 10:00:19,146 - main - INFO - Saved the best model at epoch 153.
2023-01-02 10:00:19,146 - main - INFO - Epoch 154/5000
2023-01-02 10:00:19,147 - main - INFO - ----------------------------
2023-01-02 10:00:19,147 - main - INFO - training...
2023-01-02 10:09:32,577 - main - DEBUG - Batch 500: running loss = 217589.4444
2023-01-02 10:18:46,810 - main - DEBUG - Batch 1000: running loss = 438550.9770
2023-01-02 10:27:36,477 - main - INFO - Epoch 154 - train: epoch loss = 439.0739
2023-01-02 10:27:36,478 - main - INFO - validating...
2023-01-02 10:34:28,033 - main - DEBUG - Batch 500: running loss = 147287.3548
2023-01-02 10:34:33,770 - main - INFO - Epoch 154 - val: epoch loss = 294.5417
2023-01-02 10:34:33,770 - main - INFO - Epoch 155/5000
2023-01-02 10:34:33,770 - main - INFO - ----------------------------
2023-01-02 10:34:33,771 - main - INFO - training...
2023-01-02 10:43:47,191 - main - DEBUG - Batch 500: running loss = 219501.0677
2023-01-02 10:53:01,195 - main - DEBUG - Batch 1000: running loss = 439028.4401
2023-01-02 11:02:23,955 - main - INFO - Epoch 155 - train: epoch loss = 438.5713
2023-01-02 11:02:23,956 - main - INFO - validating...
2023-01-02 11:09:52,074 - main - DEBUG - Batch 500: running loss = 148001.9189
2023-01-02 11:09:58,358 - main - INFO - Epoch 155 - val: epoch loss = 295.9690
2023-01-02 11:09:58,359 - main - INFO - Epoch 156/5000
2023-01-02 11:09:58,359 - main - INFO - ----------------------------
2023-01-02 11:09:58,360 - main - INFO - training...
2023-01-02 11:19:33,349 - main - DEBUG - Batch 500: running loss = 217735.0222
2023-01-02 11:28:51,942 - main - DEBUG - Batch 1000: running loss = 436078.6356
2023-01-02 11:37:42,624 - main - INFO - Epoch 156 - train: epoch loss = 438.0676
2023-01-02 11:37:42,625 - main - INFO - validating...
2023-01-02 11:44:38,268 - main - DEBUG - Batch 500: running loss = 147883.7764
2023-01-02 11:44:44,179 - main - INFO - Epoch 156 - val: epoch loss = 295.7356
2023-01-02 11:44:44,179 - main - INFO - Epoch 157/5000
2023-01-02 11:44:44,180 - main - INFO - ----------------------------
2023-01-02 11:44:44,180 - main - INFO - training...
2023-01-02 11:54:01,595 - main - DEBUG - Batch 500: running loss = 221800.5007
2023-01-02 12:03:15,878 - main - DEBUG - Batch 1000: running loss = 438030.8795
2023-01-02 12:12:05,678 - main - INFO - Epoch 157 - train: epoch loss = 437.7583
2023-01-02 12:12:05,678 - main - INFO - validating...
2023-01-02 12:18:57,700 - main - DEBUG - Batch 500: running loss = 147171.4346
2023-01-02 12:19:03,543 - main - INFO - Epoch 157 - val: epoch loss = 294.3090
2023-01-02 12:19:03,710 - main - INFO - Saved the best model at epoch 157.
2023-01-02 12:19:03,710 - main - INFO - Epoch 158/5000
2023-01-02 12:19:03,711 - main - INFO - ----------------------------
2023-01-02 12:19:03,711 - main - INFO - training...
